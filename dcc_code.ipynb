{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14c695aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "ename": "TesseractNotFoundError",
     "evalue": "tesseract is not installed or it's not in your PATH. See README file for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytesseract\\pytesseract.py:275\u001b[39m, in \u001b[36mrun_tesseract\u001b[39m\u001b[34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     proc = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msubprocess_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:1538\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1538\u001b[39m     hp, ht, pid, tid = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1539\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[32m   1540\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1542\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1547\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1548\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1551\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1552\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTesseractNotFoundError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     54\u001b[39m     pdf_path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mADMIN\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDownloads\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mimg20250420_19033735.pdf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     toks, table_toks = \u001b[43mtokenize_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# show first 200 tokens for brevity\u001b[39;00m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mText tokens:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mtokenize_pdf\u001b[39m\u001b[34m(pdf_path)\u001b[39m\n\u001b[32m     23\u001b[39m     pil_img  = page_img.original\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# run Tesseract\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     ocr_text = \u001b[43mpytesseract\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage_to_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpil_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     tokens += re.findall(TOK_RE, ocr_text, re.UNICODE)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# 1) extract & tokenize tables\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytesseract\\pytesseract.py:486\u001b[39m, in \u001b[36mimage_to_string\u001b[39m\u001b[34m(image, lang, config, nice, output_type, timeout)\u001b[39m\n\u001b[32m    481\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    484\u001b[39m args = [image, \u001b[33m'\u001b[39m\u001b[33mtxt\u001b[39m\u001b[33m'\u001b[39m, lang, config, nice, timeout]\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytesseract\\pytesseract.py:489\u001b[39m, in \u001b[36mimage_to_string.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    481\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    484\u001b[39m args = [image, \u001b[33m'\u001b[39m\u001b[33mtxt\u001b[39m\u001b[33m'\u001b[39m, lang, config, nice, timeout]\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    487\u001b[39m     Output.BYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(*(args + [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[32m    488\u001b[39m     Output.DICT: \u001b[38;5;28;01mlambda\u001b[39;00m: {\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m: run_and_get_output(*args)},\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     Output.STRING: \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    490\u001b[39m }[output_type]()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytesseract\\pytesseract.py:352\u001b[39m, in \u001b[36mrun_and_get_output\u001b[39m\u001b[34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[32m    342\u001b[39m     kwargs = {\n\u001b[32m    343\u001b[39m         \u001b[33m'\u001b[39m\u001b[33minput_filename\u001b[39m\u001b[33m'\u001b[39m: input_filename,\n\u001b[32m    344\u001b[39m         \u001b[33m'\u001b[39m\u001b[33moutput_filename_base\u001b[39m\u001b[33m'\u001b[39m: temp_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    349\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m: timeout,\n\u001b[32m    350\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     \u001b[43mrun_tesseract\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_output(\n\u001b[32m    354\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[33m'\u001b[39m\u001b[33moutput_filename_base\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    355\u001b[39m         return_bytes,\n\u001b[32m    356\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytesseract\\pytesseract.py:280\u001b[39m, in \u001b[36mrun_tesseract\u001b[39m\u001b[34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[39m\n\u001b[32m    278\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m TesseractNotFoundError()\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m timeout_manager(proc, timeout) \u001b[38;5;28;01mas\u001b[39;00m error_string:\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m proc.returncode:\n",
      "\u001b[31mTesseractNotFoundError\u001b[39m: tesseract is not installed or it's not in your PATH. See README file for more information."
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "def tokenize_pdf(pdf_path):\n",
    "    import re\n",
    "    import pdfplumber\n",
    "    import pytesseract\n",
    "    from PIL import Image\n",
    "\n",
    "    TOK_RE = r\"\\w+|[^\\w\\s]\"\n",
    "    tokens = []      # for text‐only tokens\n",
    "    table_tokens = []# for table tokens\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "\n",
    "            # --- OCR fallback for embedded images ---\n",
    "            if page.images:\n",
    "                # render page at 300dpi to a PIL image\n",
    "                page_img = page.to_image(resolution=300)\n",
    "                pil_img  = page_img.original\n",
    "                # run Tesseract\n",
    "                ocr_text = pytesseract.image_to_string(pil_img)\n",
    "                tokens += re.findall(TOK_RE, ocr_text, re.UNICODE)\n",
    "\n",
    "            # 1) extract & tokenize tables\n",
    "            tables = page.find_tables()\n",
    "            for table in tables:\n",
    "                for row in table.extract():\n",
    "                    for cell in row:\n",
    "                        if cell:\n",
    "                            table_tokens += re.findall(TOK_RE, cell, re.UNICODE)\n",
    "\n",
    "            # 2) extract text from the page and tokenize\n",
    "            table_bboxes = [t.bbox for t in tables]\n",
    "            words = page.extract_words()\n",
    "            for word in words:\n",
    "                word_bbox = (word['x0'], word['top'], word['x1'], word['bottom'])\n",
    "                in_table = False\n",
    "                for tb in table_bboxes:\n",
    "                    if not (word_bbox[2] < tb[0] or word_bbox[0] > tb[2] or\n",
    "                            word_bbox[3] < tb[1] or word_bbox[1] > tb[3]):\n",
    "                        in_table = True\n",
    "                        break\n",
    "                if not in_table:\n",
    "                    tokens += re.findall(TOK_RE, word['text'], re.UNICODE)\n",
    "\n",
    "    return tokens, table_tokens\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = r\"C:\\Users\\ADMIN\\Downloads\\img20250420_19033735.pdf\"\n",
    "    toks, table_toks = tokenize_pdf(pdf_path)\n",
    "    # show first 200 tokens for brevity\n",
    "    print(\"Text tokens:\")\n",
    "    print(toks)\n",
    "    print(f\"... total text tokens: {len(toks)}\")\n",
    "    \n",
    "    print(\"\\nTable tokens:\")\n",
    "    print(table_toks)\n",
    "    print(f\"... total table tokens: {len(table_toks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0c089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text tokens:\n",
      "['CALIBRATION', 'CERTIFICATE', 'No', '.', '02', '-', '2025', '-', 'FORC', '-', '0040', 'Date', 'of', 'Calibration', ':', 'February', '24', ',', '2025', 'Calibration', 'Item', ':', 'Axle', 'Weighing', 'Scale', 'Capacity', ':', '15', '000', 'kgf', 'Measurement', 'Range', ':', '0', 'kgf', 'to', '15', '000', 'kgf', 'Resolution', ':', '5', '0', 'kgf', 'Make', '/', 'Model', ':', 'Intercomp', ';', 'Serial', 'No', '.', ':', '1122YL23003', 'Customer', ':', 'SAVVICE', 'CORPORATION', '3rd', 'Floor', 'BMWC', 'Bldg', '.', ',', 'Cagayan', 'Valley', 'Road', 'Sta', '.', 'Rita', ',', 'Guiginto', ',', 'Bulacan', 'MEASUREMENT', 'RESULTS', ':', 'UNCERTAINTY', 'OF', 'MEASUREMENT', ':', 'The', 'uncertainty', 'stated', 'is', 'the', 'expanded', 'uncertainty', 'obtained', 'by', 'multiplying', 'the', 'standard', 'uncertainty', 'by', 'the', 'coverage', 'factor', 'k', '=', '2', '.', 'It', 'has', 'been', 'determined', 'in', 'accordance', 'with', 'the', '“', 'JCGM', '100', ':', '2008', 'Evaluation', 'of', 'measurement', 'data', '-', 'Guide', 'to', 'the', 'expression', 'of', 'uncertainty', 'in', 'measurement', '”', '.', 'The', 'value', 'of', 'the', 'measurand', 'lies', 'within', 'the', 'assigned', 'range', 'of', 'values', 'with', 'a', 'probability', 'of', 'approximately', '95', '%', '.', 'Page', '1', 'of', '2', 'STANDARD', 'USED', ':', 'CALIBRATION', 'PROCEDURE', ':', 'The', 'axle', 'weighing', 'scale', 'was', 'subjected', 'to', 'specified', 'force', 'values', 'in', 'comparison', 'with', 'force', 'standard', 'values', '.', 'Three', '(', '3', ')', 'series', 'of', 'increasing', 'force', 'values', 'were', 'applied', 'to', 'the', 'axle', 'weighing', 'scale', '.', 'The', 'relevant', 'references', 'for', 'this', 'axle', 'weighing', 'scale', 'calibration', 'are', 'the', 'TP', '-', 'S3', '-', 'FORC', '-', '02', ':', '\"', 'Calibration', 'of', 'Axle', 'Weighing', 'Scales', '\"', '.', 'ENVIRONMENTAL', 'CONDITIONS', ':', 'Ambient', 'Temperature', ':', '(', '21', '±', '2', ')', 'Relative', 'Humidity', ':', '(', '40', '±', '5', ')', 'REMARKS', ':', '-', 'The', 'above', 'results', 'were', 'those', 'obtained', 'at', 'the', 'time', 'of', 'calibration', 'and', 'refer', 'only', 'to', 'the', 'force', 'measuring', 'instrument', '(', 'axle', 'weighing', 'scale', ')', 'calibrated', 'in', 'static', 'compression', 'mode', '.', '-', 'No', 'adjustment', 'was', 'performed', 'on', 'the', 'axle', 'weighingscale', '.', 'The', 'user', 'should', 'determine', 'suitabilityof', 'the', 'axle', 'weighing', 'scale', 'for', 'its', 'intended', 'use', '.', 'AHDRIAN', 'CAMILO', 'C', '.', 'GERNALE', 'Science', 'Research', 'Specialist', 'II', 'RADLEY', 'F', '.', 'MANALO', 'Senior', 'Science', 'Research', 'Specialist', 'For', 'the', 'Chief', ',', 'National', 'Metrology', 'Laboratory', 'MARYNESS', 'I', '.', 'SALAZAR', ',', 'PhD', 'Head', ',', 'Pressure', 'and', 'Force', 'Standards', 'Section', 'Date', 'issued', ':', '_________________________', '-', 'End', 'of', 'Report', '-', 'Page', '2', 'of', '2', 'Calibration', 'Certificate', 'No', '.', '02', '-', '2025', '-', 'FORC', '-', '0040']\n",
      "... total text tokens: 359\n",
      "\n",
      "Table tokens:\n",
      "['Applied', 'Force', 'Indicated', 'Force', 'Deviation', '(', 'Indicated', 'Force', '-', 'Applied', 'Force', ')', 'Relative', 'Expanded', 'Uncertainty', 'Relative', 'Accuracy', 'Error', 'kgf', 'kgf', 'kgf', '%', '%', '0', '.', '00', '3', '000', '6', '000', '9', '000', '12', '000', '15', '000', '0', '.', '00', '2', '850', '5', '683', '8', '500', '11', '333', '14', '133', '0', '-', '150', '-', '317', '-', '500', '-', '667', '-', '867', '0', '.', '00', '1', '.', '04', '0', '.', '81', '0', '.', '41', '0', '.', '46', '0', '.', '39', '0', '.', '00', '5', '.', '26', '5', '.', '57', '5', '.', '88', '5', '.', '88', '6', '.', '13', 'Name', 'of', 'Standard', 'Make', '/', 'Model', 'Calibration', 'Certificate', 'No', '.', 'Traceability', 'Force', 'Measuring', 'Instrument', 'SN', '1251056K0094', 'Shimadzu', '/', 'UH', '-', 'F1000kNX', '11', '-', '2020', '-', 'FORC', '-', '0116', 'Traceable', 'to', 'the', 'SI', 'through', 'NMD', '-', 'ITDI']\n",
      "... total table tokens: 132\n"
     ]
    }
   ],
   "source": [
    "# import pdfplumber\n",
    "# import re\n",
    "\n",
    "# def tokenize_pdf(pdf_path):\n",
    "#     import re\n",
    "#     import pdfplumber\n",
    "\n",
    "#     TOK_RE = r\"\\w+|[^\\w\\s]\"\n",
    "#     tokens = []      # for text-only tokens\n",
    "#     table_tokens = [] # for table tokens\n",
    "\n",
    "#     with pdfplumber.open(pdf_path) as pdf:\n",
    "#         for page in pdf.pages:\n",
    "#             # 1) extract & tokenize tables\n",
    "#             tables = page.find_tables()\n",
    "#             for table in tables:\n",
    "#                 for row in table.extract():             # row is a list of cell‑strings\n",
    "#                     for cell in row:\n",
    "#                         if cell:\n",
    "#                             table_tokens += re.findall(TOK_RE, cell, re.UNICODE)\n",
    "\n",
    "#             # 2) extract text from the page and tokenize\n",
    "#             # Create a list of table bounding boxes to check against\n",
    "#             table_bboxes = [table.bbox for table in tables]\n",
    "            \n",
    "#             # Extract all words from the page with their bounding boxes\n",
    "#             words = page.extract_words()\n",
    "#             for word in words:\n",
    "#                 # Check if this word's bbox overlaps with any table bbox\n",
    "#                 word_bbox = (word['x0'], word['top'], word['x1'], word['bottom'])\n",
    "#                 in_table = False\n",
    "#                 for table_bbox in table_bboxes:\n",
    "#                     # Simple overlap check: not (word is completely left, right, above or below table)\n",
    "#                     if not (word_bbox[2] < table_bbox[0] or  # word is left of table\n",
    "#                             word_bbox[0] > table_bbox[2] or  # word is right of table\n",
    "#                             word_bbox[3] < table_bbox[1] or  # word is above table\n",
    "#                             word_bbox[1] > table_bbox[3]):   # word is below table\n",
    "#                         in_table = True\n",
    "#                         break\n",
    "                \n",
    "#                 # Only add tokens from words not in tables\n",
    "#                 if not in_table:\n",
    "#                     tokens += re.findall(TOK_RE, word['text'], re.UNICODE)\n",
    "\n",
    "#     return tokens, table_tokens\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     pdf_path = r\"C:\\Work\\DOST-ITDI\\Digital-Calibration-Certificate-for-National-Metrology-Laboratory-of-the-Philippines\\valid pdf\\3.pdf\"\n",
    "#     toks, table_toks = tokenize_pdf(pdf_path)\n",
    "#     # show first 200 tokens for brevity\n",
    "#     print(\"Text tokens:\")\n",
    "#     print(toks)\n",
    "#     print(f\"... total text tokens: {len(toks)}\")\n",
    "    \n",
    "#     print(\"\\nTable tokens:\")\n",
    "#     print(table_toks)\n",
    "#     print(f\"... total table tokens: {len(table_toks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49cc8023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text(path):\n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        return \"\\n\".join(page.extract_text() or \"\" for page in pdf.pages)\n",
    "\n",
    "pdf_path = r\"C:\\Users\\ADMIN\\Documents\\GitHub\\Digital-Calibration-Certificate-for-National-Metrology-Laboratory-of-the-Philippines\\valid pdf\\tensilemachine.pdf\"\n",
    "raw_text = extract_text(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cae5ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CALIBRATION CERTIFICATE\\nNo. 02-2019-FORC-0028\\nDate of Calibration : March 13, 2019\\nCalibration Item : Tensile Testing Machine\\nCapacity : 2000 kgf\\nMeasurement Range : 0 kgf to 1000 kgf\\nResolution : 0 . 1 :\\nMake / Model : Gotech/AI-7000-M (Load Cell); Fairbanks/GT1110 (Indicator)\\nSerial No. : TC150801739 (Load Cell); t1232131 (Indicator)\\nCustomer : SYCWIN COATING & WIRES, INC.\\n93 Joy St., Grace Village, Balingasa, Quezon City\\nMEASUREMENT RESULTS:\\nRelative Relative\\nApplied Relative\\nIndicated Force Expanded Repeatability\\nForce Accuracy Error Class\\nUncertainty Error\\nkN kN kN % % %\\n0.0 0.00 0.00 0.00 0.00 0.00 -\\n100.0 100.00 100.76 0.37 -0.76 0.58 1\\n200.0 200.00 200.19 0.18 -0.10 0.13 1\\n300.0 300.00 300.12 0.27 -0.04 0.35 1\\n400.0 400.00 400.12 0.16 -0.04 0.02 1\\n500.0 500.00 499.95 0.19 0.02 0.17 1\\nUNCERTAINTY OF MEASUREMENT:\\nThe uncertainty stated is the expanded uncertainty obtained by multiplying the standard uncertainty\\nby the coverage factor k = 2. It has been determined in accordance with the “JCGM 100:2008\\nEvaluation of measurement data- Guide to the Expression of Uncertainty in measurement ”. The\\nvalue of the measurand lies within the assigned range of values with a probability of approximately\\n95%.\\nPage 1 of 2\\nSTANDARD USED :\\nName of Standard Make/Model Calibration Certificate No. Traceability\\nLoad Cell Traceable to SI through\\nHBM/U15 0\\nSN XXXXX KRISS - Korea\\nCALIBRATION PROCEDURE:\\nThe testing machine under calibration was subjected to specified force values which were applied\\non the force-proving instrument and readings were noted.\\nThe relevant reference document for this calibration is ISO 7500-1:2018, Metallic materials –\\nVerification of static uniaxial testing machines.\\nENVIRONMENTAL CONDITIONS:\\nAmbient Temperature : (25 ± 2) °C\\nRelative Humidity : (54.5 ± 5) %\\nREMARKS:\\n- The above results were those obtained at the time of calibration and refer only to the testing\\nmachine calibrated in compression.\\n- No adjustment was performed on the testing machine. The user should determine suitability of\\nthe testing machine for its intended use.\\n- The testing machine was calibrated at the Quality Assurance Laboratory of SYCWINCOATING\\n& WIRES, INC. at 93 Joy St., Grace Village, Balingasa, Quezon City.\\nAHDRIAN CAMILO C. GERNALE\\nScience Research Specialist I\\nFor the Chief, National Metrology Laboratory\\nRADLEY F. MANALO\\nDeputy Head, Pressure and Force Standards Section\\nPage 2 of 2\\nCalibration Certificate No. 02-2019-FORC-0028'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "063a0b1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'toks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 176\u001b[39m\n\u001b[32m    171\u001b[39m         info[key] = info[key].replace(\u001b[33m'\u001b[39m\u001b[33m ,\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m,\u001b[39m\u001b[33m'\u001b[39m).replace(\u001b[33m'\u001b[39m\u001b[33m .\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m).replace(\u001b[33m'\u001b[39m\u001b[33m ;\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m;\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m info\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m info = extract_calibration_info(\u001b[43mtoks\u001b[49m)\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# Print the extracted information\u001b[39;00m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m info.items():\n",
      "\u001b[31mNameError\u001b[39m: name 'toks' is not defined"
     ]
    }
   ],
   "source": [
    "def extract_calibration_info(tokens):\n",
    "    # Initialize variables to store extracted information\n",
    "    info = {\n",
    "        'certificate_number': '',\n",
    "        'calibration_date': '',\n",
    "        'item': '',\n",
    "        'capacity': '',\n",
    "        'measurement_range': '',\n",
    "        'resolution': '',\n",
    "        'make_model': '',\n",
    "        'serial_number': '',\n",
    "        'customer': '',\n",
    "        'customer_address': ''\n",
    "    }\n",
    "    \n",
    "    # List of valid month names for date detection\n",
    "    months = ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "              'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    \n",
    "    # Extract certificate number\n",
    "    try:\n",
    "        cert_idx = -1\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token == 'No' and i + 1 < len(tokens) and tokens[i + 1] == '.':\n",
    "                cert_idx = i + 2\n",
    "                break\n",
    "        \n",
    "        if cert_idx != -1:\n",
    "            # Build certificate number by joining tokens until 'Date' or other delimiter\n",
    "            cert_parts = []\n",
    "            current_idx = cert_idx\n",
    "            while current_idx < len(tokens) and tokens[current_idx] not in ['Date', 'Calibration']:\n",
    "                cert_parts.append(tokens[current_idx])\n",
    "                current_idx += 1\n",
    "            \n",
    "            # Join the parts to form complete certificate number\n",
    "            info['certificate_number'] = ''.join(cert_parts)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Extract calibration date by looking for a valid month\n",
    "    try:\n",
    "        # Find the month in the tokens\n",
    "        month_idx = -1\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token in months:\n",
    "                month_idx = i\n",
    "                break\n",
    "        \n",
    "        if month_idx != -1:\n",
    "            # Extract the complete date (month, day, year)\n",
    "            # Typically the format is: Month Day, Year\n",
    "            date_parts = []\n",
    "            current_idx = month_idx\n",
    "            # Add month\n",
    "            date_parts.append(tokens[current_idx])\n",
    "            current_idx += 1\n",
    "            \n",
    "            # Add day\n",
    "            if current_idx < len(tokens) and tokens[current_idx].isdigit():\n",
    "                date_parts.append(tokens[current_idx])\n",
    "                current_idx += 1\n",
    "            \n",
    "            # Add comma if present\n",
    "            if current_idx < len(tokens) and tokens[current_idx] == ',':\n",
    "                date_parts.append(tokens[current_idx])\n",
    "                current_idx += 1\n",
    "            \n",
    "            # Add year\n",
    "            if current_idx < len(tokens) and tokens[current_idx].isdigit():\n",
    "                date_parts.append(tokens[current_idx])\n",
    "            \n",
    "            # Join the parts to form complete date\n",
    "            info['calibration_date'] = ' '.join(date_parts)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Extract item\n",
    "    try:\n",
    "        item_idx = tokens.index('Item') + 2  # Skip 'Item', ':'\n",
    "        capacity_idx = tokens.index('Capacity')\n",
    "        info['item'] = ' '.join(tokens[item_idx:capacity_idx])\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    # Extract capacity\n",
    "    try:\n",
    "        capacity_idx = tokens.index('Capacity') + 2  # Skip 'Capacity', ':'\n",
    "        measurement_idx = tokens.index('Measurement')\n",
    "        # Join the numbers and unit\n",
    "        info['capacity'] = ' '.join(tokens[capacity_idx:measurement_idx])\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    # Extract measurement range\n",
    "    try:\n",
    "        range_idx = tokens.index('Range') + 2  # Skip 'Range', ':'\n",
    "        resolution_idx = tokens.index('Resolution')\n",
    "        info['measurement_range'] = ' '.join(tokens[range_idx:resolution_idx])\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    # Extract resolution\n",
    "    try:\n",
    "        resolution_idx = tokens.index('Resolution') + 2  # Skip 'Resolution', ':'\n",
    "        make_idx = tokens.index('Make')\n",
    "        # Join the resolution value\n",
    "        info['resolution'] = ''.join(tokens[resolution_idx:make_idx])\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    # Extract make/model\n",
    "    try:\n",
    "        make_idx = tokens.index('Model') + 2  # Skip 'Model', ':'\n",
    "        serial_idx = tokens.index('Serial')\n",
    "        info['make_model'] = ' '.join(tokens[make_idx:serial_idx])\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    # Extract serial number\n",
    "    try:\n",
    "        serial_idx = tokens.index('Serial') + 4  # Skip 'Serial', 'No', '.', ':'\n",
    "        customer_idx = tokens.index('Customer')\n",
    "        info['serial_number'] = tokens[serial_idx]\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    # Extract customer and address with improved logic\n",
    "    try:\n",
    "        customer_idx = tokens.index('Customer') + 2  # Skip 'Customer', ':'\n",
    "        \n",
    "        # First, identify the customer name\n",
    "        customer_name_tokens = []\n",
    "        address_start_idx = -1\n",
    "        \n",
    "        # Look for address indicators\n",
    "        for i in range(customer_idx, len(tokens)):\n",
    "            if tokens[i] in ['Floor', 'St', 'Street', 'Ave', 'Avenue', 'Road', 'Bldg', '3rd']:\n",
    "                address_start_idx = i - 1  # Start from the word before the identifier\n",
    "                break\n",
    "            if i > customer_idx:  # Add tokens to customer name until we find address start\n",
    "                customer_name_tokens.append(tokens[i])\n",
    "        \n",
    "        # If no address indicators found, use a reasonable cutoff\n",
    "        if address_start_idx == -1:\n",
    "            address_start_idx = min(customer_idx + len(customer_name_tokens), len(tokens) - 1)\n",
    "        \n",
    "        # Set customer name\n",
    "        info['customer'] = ' '.join(customer_name_tokens)\n",
    "        \n",
    "        # Now extract the address\n",
    "        address_end_idx = -1\n",
    "        for i in range(address_start_idx, len(tokens)):\n",
    "            if tokens[i] in ['MEASUREMENT', 'RESULTS', 'UNCERTAINTY']:\n",
    "                address_end_idx = i\n",
    "                break\n",
    "        \n",
    "        if address_end_idx == -1:\n",
    "            address_end_idx = len(tokens) - 1  # If no end marker found, go to end\n",
    "            \n",
    "        # Extract address, starting from the address indicator\n",
    "        info['customer_address'] = ' '.join(tokens[address_start_idx:address_end_idx])\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    # Clean up data - remove any unwanted characters or fix formatting issues\n",
    "    for key in info:\n",
    "        # Remove extra spaces\n",
    "        info[key] = ' '.join(info[key].split())\n",
    "        # Fix common issues\n",
    "        info[key] = info[key].replace(' ,', ',').replace(' .', '.').replace(' ;', ';')\n",
    "    \n",
    "    return info\n",
    "\n",
    "\n",
    "info = extract_calibration_info(toks)\n",
    "\n",
    "# Print the extracted information\n",
    "for key, value in info.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29851f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cert_no': '02-2019-FORC-0028',\n",
       " 'calibration_date': 'March13,2019',\n",
       " 'calibration_item': 'Tensile Testing Machine',\n",
       " 'capacity': '2000 kgf',\n",
       " 'measurement_range': '0 kgf to 1000 kgf',\n",
       " 'resolution': '0.1:',\n",
       " 'make_model': 'Gotech/AI-7000-M(LoadCell);Fairbanks/GT1110(Indicator)',\n",
       " 'serial_no': 'TC150801739(LoadCell);t1232131(Indicator)',\n",
       " 'customer': 'SYCWINCOATING&WIRES,INC.93JoySt.,GraceVillage,Balingasa,QuezonCity'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # define token‐based start/end markers (all in lowercase)\n",
    "# FIELD_PATTERNS_TOK = {\n",
    "#     \"cert_no\": ([\"calibration\",\"certificate\",\"no\",\".\"], [\"date\",\"of\",\"calibration\",\":\"]),\n",
    "#     \"calibration_date\": ([\"date\",\"of\",\"calibration\",\":\"],  [\"calibration\",\"item\",\":\"]),\n",
    "#     \"calibration_item\": ([\"calibration\",\"item\",\":\"], [\"capacity\",\":\"]),\n",
    "#     \"capacity\": ([\"capacity\",\":\"], [\"measurement\",\"range\",\":\"]),\n",
    "#     \"measurement_range\": ([\"measurement\",\"range\",\":\"], [\"resolution\",\":\"]),\n",
    "#     \"resolution\": ([\"resolution\",\":\"], [\"make\",\"/\",\"model\",\":\"]),\n",
    "#     \"make_model\": ([\"make\",\"/\",\"model\",\":\"], [\"serial\",\"no\",\".\",\":\"]),\n",
    "#     \"serial_no\": ([\"serial\",\"no\",\".\",\":\"], [\"customer\",\":\"]),\n",
    "#     \"customer\": ([\"customer\",\":\"], [\"measurement\",\"results\",\":\"]),\n",
    "# }\n",
    "\n",
    "# # for keys where you want spaces between tokens\n",
    "# SPACE_KEYS = {\"calibration_item\", \"capacity\", \"measurement_range\"}  # ← customize\n",
    "\n",
    "# def find_sublist(lst, sub):\n",
    "#     \"\"\"Return first index where sub appears in lst, else -1.\"\"\"\n",
    "#     n, m = len(lst), len(sub)\n",
    "#     for i in range(n - m + 1):\n",
    "#         if lst[i:i+m] == sub:\n",
    "#             return i\n",
    "#     return -1\n",
    "\n",
    "# tokens_norm = [t.lower() for t in toks]\n",
    "# data = {}\n",
    "\n",
    "# for key, (start_seq, end_seq) in FIELD_PATTERNS_TOK.items():\n",
    "#     i = find_sublist(tokens_norm, start_seq)\n",
    "#     if i < 0:\n",
    "#         data[key] = None\n",
    "#         continue\n",
    "\n",
    "#     j_rel = find_sublist(tokens_norm[i+len(start_seq):], end_seq)\n",
    "#     if j_rel < 0:\n",
    "#         data[key] = None\n",
    "#         continue\n",
    "\n",
    "#     j = i + len(start_seq) + j_rel\n",
    "#     slice_tokens = toks[i+len(start_seq):j]\n",
    "\n",
    "#     if key in SPACE_KEYS:\n",
    "#         # join with spaces\n",
    "#         data[key] = \" \".join(slice_tokens).strip()\n",
    "#     else:\n",
    "#         # join without spaces\n",
    "#         data[key] = \"\".join(slice_tokens).strip()\n",
    "\n",
    "# data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82afc7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# 1) your extracted values\n",
    "software_name          = \"DigiCert\" #STATIC\n",
    "software_release       = \"1.0\" #STATIC\n",
    "country_code_iso       = \"PH\" #STATIC\n",
    "used_lang_code         = \"en\" #STATIC\n",
    "mandatory_lang_code    = \"en\" #STATIC\n",
    "# take the actual certificate number string, not the token list\n",
    "\n",
    "# CERTIFICATE NO. (TSR Number)\n",
    "unique_identifier = data.get(\"cert_no\", \"\")  \n",
    "\n",
    "\n",
    "# DATE\n",
    "raw_date = data.get(\"calibration_date\", \"\")\n",
    "# ensure a space between month name and day, then normalize commas and whitespace\n",
    "step1 = re.sub(r\"([A-Za-z]+)(\\d)\", r\"\\1 \\2\", raw_date)\n",
    "step2 = step1.replace(\",\", \", \")\n",
    "norm  = re.sub(r\"\\s+\", \" \", step2).strip()\n",
    "\n",
    "try:\n",
    "    # parse “FullMonthName DD, YYYY” → “YYYY‑MM‑DD”\n",
    "    dt = datetime.strptime(norm, \"%B %d, %Y\")\n",
    "    begin_performance_date = dt.strftime(\"%Y-%m-%d\")\n",
    "except ValueError:\n",
    "    begin_performance_date = \"\"\n",
    "\n",
    "end_performance_date   = \"\"\n",
    "\n",
    "#PERFORMANCE LOCATION\n",
    "performance_location   = \"LABORATORY\" #ONSITE or LABORATORY\n",
    "\n",
    "\n",
    "# Calibration item\n",
    "item_name             = data.get(\"calibration_item\", \"\")\n",
    "equipment_ref_type    = \"\" \n",
    "equipment_reference   = \"\" \n",
    "equipment_class_id    = \"\"\n",
    "\n",
    "#Standard item\n",
    "subitem_name    = \"\"\n",
    "subitem_model         = \"\"\n",
    "ident_issuer          = \"\"\n",
    "ident_value           = \"\"\n",
    "ident_name            = \"\"\n",
    "\n",
    "lab_code              = \"FORC\" #STATIC\n",
    "lab_contact_name      = \"National Metrology Laboratory - Industrial Technology Development Institute\" #STATIC\n",
    "lab_city              = \"Taguig\" #STATIC\n",
    "lab_country_code      = \"PH\" #STATIC\n",
    "lab_post_code         = \"1633\" #STATIC\n",
    "lab_street            = \"General Santos Ave\" #STATIC\n",
    "\n",
    "resp1_name            = \"\"\n",
    "resp1_role            = \"\"\n",
    "resp2_name            = \"\"\n",
    "resp2_role            = \"\"\n",
    "resp3_name            = \"\"\n",
    "resp3_role            = \"\"\n",
    "\n",
    "customer_name         = \"\"\n",
    "customer_city         = \"\"\n",
    "customer_country_code = \"PH\" #STATIC\n",
    "customer_post_code    = \"\"\n",
    "customer_street       = \"\"\n",
    "customer_street_no    = \"\"\n",
    "\n",
    "comment               = \"\"\n",
    "\n",
    "# 2) parse + register namespaces\n",
    "template = r\"valid xml\\empty.xml\"\n",
    "output   = r\"valid xml\\filled.xml\"\n",
    "\n",
    "ns = {\n",
    "    \"dcc\": \"https://ptb.de/dcc\",\n",
    "    \"si\":  \"https://ptb.de/si\"\n",
    "}\n",
    "for prefix, uri in ns.items():\n",
    "    ET.register_namespace(prefix, uri)\n",
    "\n",
    "tree = ET.parse(template)\n",
    "root = tree.getroot()\n",
    "\n",
    "def set_text(elem, txt, lang=None):\n",
    "    if txt is None:\n",
    "        return\n",
    "    elem.text = txt\n",
    "    if lang:\n",
    "        elem.set(\"lang\", lang)\n",
    "\n",
    "# 3) fill in\n",
    "set_text(root.find(\".//dcc:software/dcc:name/dcc:content\", ns), software_name)\n",
    "set_text(root.find(\".//dcc:software/dcc:release\",           ns), software_release)\n",
    "set_text(root.find(\".//dcc:coreData/dcc:countryCodeISO3166_1\", ns), country_code_iso)\n",
    "set_text(root.find(\".//dcc:coreData/dcc:usedLangCodeISO639_1\",  ns), used_lang_code)\n",
    "set_text(root.find(\".//dcc:coreData/dcc:mandatoryLangCodeISO639_1\", ns), mandatory_lang_code)\n",
    "set_text(root.find(\".//dcc:coreData/dcc:uniqueIdentifier\",       ns), unique_identifier)\n",
    "set_text(root.find(\".//dcc:coreData/dcc:beginPerformanceDate\",   ns), begin_performance_date)\n",
    "set_text(root.find(\".//dcc:coreData/dcc:endPerformanceDate\",     ns), end_performance_date)\n",
    "set_text(root.find(\".//dcc:coreData/dcc:performanceLocation\",    ns), performance_location)\n",
    "\n",
    "# items\n",
    "set_text(root.find(\".//dcc:items/dcc:name/dcc:content\", ns), item_name, lang=used_lang_code)\n",
    "ec = root.find(\".//dcc:items/dcc:equipmentClass\", ns)\n",
    "if ec is not None:\n",
    "    ec.set(\"refType\", equipment_ref_type)\n",
    "    set_text(ec.find(\"dcc:reference\", ns), equipment_reference)\n",
    "    set_text(ec.find(\"dcc:classID\",   ns), equipment_class_id)\n",
    "\n",
    "# sub‐item + identification\n",
    "si_el = root.find(\".//dcc:item\", ns)\n",
    "if si_el is not None:\n",
    "    set_text(si_el.find(\"dcc:name/dcc:content\", ns), subitem_name, lang=used_lang_code)\n",
    "    set_text(si_el.find(\"dcc:model\", ns), subitem_model)\n",
    "    ident = si_el.find(\"dcc:identifications/dcc:identification\", ns)\n",
    "    if ident is not None:\n",
    "        set_text(ident.find(\"dcc:issuer\",               ns), ident_issuer)\n",
    "        set_text(ident.find(\"dcc:value\",                ns), ident_value)\n",
    "        set_text(ident.find(\"dcc:name/dcc:content\",     ns), ident_name, lang=used_lang_code)\n",
    "\n",
    "# laboratory\n",
    "set_text(root.find(\".//dcc:calibrationLaboratory/dcc:calibrationLaboratoryCode\", ns), lab_code)\n",
    "set_text(root.find(\".//dcc:calibrationLaboratory/dcc:contact/dcc:name/dcc:content\", ns), lab_contact_name, lang=used_lang_code)\n",
    "set_text(root.find(\".//dcc:calibrationLaboratory/dcc:contact/dcc:location/dcc:city\",        ns), lab_city)\n",
    "set_text(root.find(\".//dcc:calibrationLaboratory/dcc:contact/dcc:location/dcc:countryCode\",   ns), lab_country_code)\n",
    "set_text(root.find(\".//dcc:calibrationLaboratory/dcc:contact/dcc:location/dcc:postCode\",     ns), lab_post_code)\n",
    "set_text(root.find(\".//dcc:calibrationLaboratory/dcc:contact/dcc:location/dcc:street\",       ns), lab_street)\n",
    "\n",
    "# respPersons\n",
    "resp_nodes = root.findall(\".//dcc:respPersons/dcc:respPerson\", ns)\n",
    "for idx, (name, role) in enumerate([\n",
    "    (resp1_name, resp1_role),\n",
    "    (resp2_name, resp2_role),\n",
    "    (resp3_name, resp3_role),\n",
    "]):\n",
    "    if idx < len(resp_nodes):\n",
    "        rp = resp_nodes[idx]\n",
    "        set_text(rp.find(\"dcc:person/dcc:name/dcc:content\", ns), name, lang=used_lang_code)\n",
    "        set_text(rp.find(\"dcc:role\", ns), role)\n",
    "\n",
    "# customer\n",
    "cust = root.find(\".//dcc:customer\", ns)\n",
    "if cust is not None:\n",
    "    set_text(cust.find(\"dcc:name/dcc:content\", ns), customer_name, lang=used_lang_code)\n",
    "    loc = cust.find(\"dcc:location\", ns)\n",
    "    set_text(loc.find(\"dcc:city\", ns),        customer_city)\n",
    "    set_text(loc.find(\"dcc:countryCode\", ns), customer_country_code)\n",
    "    set_text(loc.find(\"dcc:postCode\", ns),    customer_post_code)\n",
    "    set_text(loc.find(\"dcc:street\", ns),      customer_street)\n",
    "    set_text(loc.find(\"dcc:streetNo\", ns),    customer_street_no)\n",
    "\n",
    "# comment\n",
    "set_text(root.find(\".//dcc:comment\", ns), comment)\n",
    "\n",
    "# 4) write\n",
    "tree.write(output, encoding=\"utf-8\", xml_declaration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fd70e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text tokens:\n",
      "['CALIBRATION', 'CERTIFICATE', 'No', '.', '02', '-', '2025', '-', 'FORC', '-', '0043', 'Date', 'of', 'Calibration', ':', 'February', '24', ',', '2025', 'Calibration', 'Item', ':', 'Axle', 'Weighing', 'Scale', 'Capacity', ':', '15', '000', 'kgf', 'Measurement', 'Range', ':', '0', 'kgf', 'to', '15', '000', 'kgf', 'Resolution', ':', '5', '0', 'kgf', 'Make', '/', 'Model', ':', 'Intercomp', ';', 'Serial', 'No', '.', ':', '1122YL23002', 'Customer', ':', 'SAVVICE', 'CORPORATION', '3rd', 'Floor', 'BMWC', 'Bldg', '.', ',', 'Cagayan', 'Valley', 'Road', 'Sta', '.', 'Rita', ',', 'Guiginto', ',', 'Bulacan', 'MEASUREMENT', 'RESULTS', ':', 'UNCERTAINTY', 'OF', 'MEASUREMENT', ':', 'The', 'uncertainty', 'stated', 'is', 'the', 'expanded', 'uncertainty', 'obtained', 'by', 'multiplying', 'the', 'standard', 'uncertainty', 'by', 'the', 'coverage', 'factor', 'k', '=', '2', '.', 'It', 'has', 'been', 'determined', 'in', 'accordance', 'with', 'the', '“', 'JCGM', '100', ':', '2008', 'Evaluation', 'of', 'measurement', 'data', '-', 'Guide', 'to', 'the', 'expression', 'of', 'uncertainty', 'in', 'measurement', '”', '.', 'The', 'value', 'of', 'the', 'measurand', 'lies', 'within', 'the', 'assigned', 'range', 'of', 'values', 'with', 'a', 'probability', 'of', 'approximately', '95', '%', '.', 'Page', '1', 'of', '2', 'STANDARD', 'USED', ':', 'CALIBRATION', 'PROCEDURE', ':', 'The', 'axle', 'weighing', 'scale', 'was', 'subjected', 'to', 'specified', 'force', 'values', 'in', 'comparison', 'with', 'force', 'standard', 'values', '.', 'Three', '(', '3', ')', 'series', 'of', 'increasing', 'force', 'values', 'were', 'applied', 'to', 'the', 'axle', 'weighing', 'scale', '.', 'The', 'relevant', 'references', 'for', 'this', 'axle', 'weighing', 'scale', 'calibration', 'are', 'the', 'TP', '-', 'S3', '-', 'FORC', '-', '02', ':', '\"', 'Calibration', 'of', 'Axle', 'Weighing', 'Scales', '\"', '.', 'ENVIRONMENTAL', 'CONDITIONS', ':', 'Ambient', 'Temperature', ':', '(', '22', '±', '2', ')', 'Relative', 'Humidity', ':', '(', '40', '±', '5', ')', 'REMARKS', ':', '-', 'The', 'above', 'results', 'were', 'those', 'obtained', 'at', 'the', 'time', 'of', 'calibration', 'and', 'refer', 'only', 'to', 'the', 'force', 'measuring', 'instrument', '(', 'axle', 'weighing', 'scale', ')', 'calibrated', 'in', 'static', 'compression', 'mode', '.', '-', 'No', 'adjustment', 'was', 'performed', 'on', 'the', 'axle', 'weighingscale', '.', 'The', 'user', 'should', 'determine', 'suitabilityof', 'the', 'axle', 'weighing', 'scale', 'for', 'its', 'intended', 'use', '.', 'AHDRIAN', 'CAMILO', 'C', '.', 'GERNALE', 'Science', 'Research', 'Specialist', 'II', 'RADLEY', 'F', '.', 'MANALO', 'Senior', 'Science', 'Research', 'Specialist', 'For', 'the', 'Chief', ',', 'National', 'Metrology', 'Laboratory', 'MARYNESS', 'I', '.', 'SALAZAR', ',', 'PhD', 'Head', ',', 'Pressure', 'and', 'Force', 'Standards', 'Section', 'Date', 'issued', ':', '_________________________', '-', 'End', 'of', 'Report', '-', 'Page', '2', 'of', '2', 'Calibration', 'Certificate', 'No', '.', '02', '-', '2025', '-', 'FORC', '-', '0043']\n",
      "... total text tokens: 359\n",
      "\n",
      "Table tokens:\n",
      "['Applied', 'Force', 'Indicated', 'Force', 'Deviation', '(', 'Indicated', 'Force', '-', 'Applied', 'Force', ')', 'Relative', 'Expanded', 'Uncertainty', 'Relative', 'Accuracy', 'Error', 'kgf', 'kgf', 'kgf', '%', '%', '0', '.', '00', '3', '000', '6', '000', '9', '000', '12', '000', '15', '000', '0', '.', '00', '2', '850', '5', '700', '8', '550', '11', '433', '14', '300', '0', '-', '150', '-', '300', '-', '450', '-', '567', '-', '700', '0', '.', '00', '1', '.', '04', '0', '.', '56', '0', '.', '41', '0', '.', '45', '0', '.', '31', '0', '.', '00', '5', '.', '26', '5', '.', '26', '5', '.', '26', '4', '.', '96', '4', '.', '90', 'Name', 'of', 'Standard', 'Make', '/', 'Model', 'Calibration', 'Certificate', 'No', '.', 'Traceability', 'Force', 'Measuring', 'Instrument', 'SN', '1251056K0094', 'Shimadzu', '/', 'UH', '-', 'F1000kNX', '11', '-', '2020', '-', 'FORC', '-', '0116', 'Traceable', 'to', 'the', 'SI', 'through', 'NMD', '-', 'ITDI']\n",
      "... total table tokens: 132\n"
     ]
    }
   ],
   "source": [
    "# import pdfplumber\n",
    "# import re\n",
    "\n",
    "# def tokenize_pdf(pdf_path):\n",
    "#     import re\n",
    "#     import pdfplumber\n",
    "\n",
    "#     TOK_RE = r\"\\w+|[^\\w\\s]\"\n",
    "#     tokens = []      # for text-only tokens\n",
    "#     table_tokens = [] # for table tokens\n",
    "\n",
    "#     with pdfplumber.open(pdf_path) as pdf:\n",
    "#         for page in pdf.pages:\n",
    "#             # 1) extract & tokenize tables\n",
    "#             tables = page.find_tables()\n",
    "#             for table in tables:\n",
    "#                 for row in table.extract():             # row is a list of cell‑strings\n",
    "#                     for cell in row:\n",
    "#                         if cell:\n",
    "#                             table_tokens += re.findall(TOK_RE, cell, re.UNICODE)\n",
    "\n",
    "#             # 2) extract text from the page and tokenize\n",
    "#             # Create a list of table bounding boxes to check against\n",
    "#             table_bboxes = [table.bbox for table in tables]\n",
    "            \n",
    "#             # Extract all words from the page with their bounding boxes\n",
    "#             words = page.extract_words()\n",
    "#             for word in words:\n",
    "#                 # Check if this word's bbox overlaps with any table bbox\n",
    "#                 word_bbox = (word['x0'], word['top'], word['x1'], word['bottom'])\n",
    "#                 in_table = False\n",
    "#                 for table_bbox in table_bboxes:\n",
    "#                     # Simple overlap check: not (word is completely left, right, above or below table)\n",
    "#                     if not (word_bbox[2] < table_bbox[0] or  # word is left of table\n",
    "#                             word_bbox[0] > table_bbox[2] or  # word is right of table\n",
    "#                             word_bbox[3] < table_bbox[1] or  # word is above table\n",
    "#                             word_bbox[1] > table_bbox[3]):   # word is below table\n",
    "#                         in_table = True\n",
    "#                         break\n",
    "                \n",
    "#                 # Only add tokens from words not in tables\n",
    "#                 if not in_table:\n",
    "#                     tokens += re.findall(TOK_RE, word['text'], re.UNICODE)\n",
    "\n",
    "#     return tokens, table_tokens\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     pdf_path = r\"C:\\Work\\DOST-ITDI\\Digital-Calibration-Certificate-for-National-Metrology-Laboratory-of-the-Philippines\\valid pdf\\1.pdf\"\n",
    "#     toks, table_toks = tokenize_pdf(pdf_path)\n",
    "#     # show first 200 tokens for brevity\n",
    "#     print(\"Text tokens:\")\n",
    "#     print(toks)\n",
    "#     print(f\"... total text tokens: {len(toks)}\")\n",
    "    \n",
    "#     print(\"\\nTable tokens:\")\n",
    "#     print(table_toks)\n",
    "#     print(f\"... total table tokens: {len(table_toks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58984ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cert_no': '02-2025-FORC-0043',\n",
       " 'calibration_date': 'February24,2025',\n",
       " 'calibration_item': 'Axle Weighing Scale',\n",
       " 'capacity': '15 000 kgf',\n",
       " 'measurement_range': '0kgfto15000kgf',\n",
       " 'resolution': '50kgf',\n",
       " 'make_model': 'Intercomp;',\n",
       " 'serial_no': '1122YL23002'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # define token‐based start/end markers (all in lowercase)\n",
    "# FIELD_PATTERNS_TOK = {\n",
    "#     \"cert_no\": ([\"calibration\",\"certificate\",\"no\",\".\"], [\"date\",\"of\",\"calibration\",\":\"]),\n",
    "#     \"calibration_date\": ([\"date\",\"of\",\"calibration\",\":\"],  [\"calibration\",\"item\",\":\"]),\n",
    "#     \"calibration_item\": ([\"calibration\",\"item\",\":\"], [\"capacity\",\":\"]),\n",
    "#     \"capacity\": ([\"capacity\",\":\"], [\"measurement\",\"range\",\":\"]),\n",
    "#     \"measurement_range\": ([\"measurement\",\"range\",\":\"], [\"resolution\",\":\"]),\n",
    "#     \"resolution\": ([\"resolution\",\":\"], [\"make\",\"/\",\"model\",\":\"]),\n",
    "#     \"make_model\": ([\"make\",\"/\",\"model\",\":\"], [\"serial\",\"no\",\".\",\":\"]),\n",
    "#     \"serial_no\": ([\"serial\",\"no\",\".\",\":\"], [\"customer\",\":\"])\n",
    "# }\n",
    "\n",
    "# # for keys where you want spaces between tokens\n",
    "# SPACE_KEYS = {\"calibration_item\", \"capacity\"}  # ← customize\n",
    "\n",
    "# def find_sublist(lst, sub):\n",
    "#     \"\"\"Return first index where sub appears in lst, else -1.\"\"\"\n",
    "#     n, m = len(lst), len(sub)\n",
    "#     for i in range(n - m + 1):\n",
    "#         if lst[i:i+m] == sub:\n",
    "#             return i\n",
    "#     return -1\n",
    "\n",
    "# tokens_norm = [t.lower() for t in toks]\n",
    "# data = {}\n",
    "\n",
    "# for key, (start_seq, end_seq) in FIELD_PATTERNS_TOK.items():\n",
    "#     i = find_sublist(tokens_norm, start_seq)\n",
    "#     if i < 0:\n",
    "#         data[key] = None\n",
    "#         continue\n",
    "\n",
    "#     j_rel = find_sublist(tokens_norm[i+len(start_seq):], end_seq)\n",
    "#     if j_rel < 0:\n",
    "#         data[key] = None\n",
    "#         continue\n",
    "\n",
    "#     j = i + len(start_seq) + j_rel\n",
    "#     slice_tokens = toks[i+len(start_seq):j]\n",
    "\n",
    "#     if key in SPACE_KEYS:\n",
    "#         # join with spaces\n",
    "#         data[key] = \" \".join(slice_tokens).strip()\n",
    "#     else:\n",
    "#         # join without spaces\n",
    "#         data[key] = \"\".join(slice_tokens).strip()\n",
    "\n",
    "# data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0e6c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# import re\n",
    "\n",
    "# import xml.etree.ElementTree as ET\n",
    "\n",
    "# # 1) your extracted values\n",
    "# software_name          = \"DigiCert\" #STATIC\n",
    "# software_release       = \"1.0\" #STATIC\n",
    "# country_code_iso       = \"PH\" #STATIC\n",
    "# used_lang_code         = \"en\" #STATIC\n",
    "# mandatory_lang_code    = \"en\" #STATIC\n",
    "# # take the actual certificate number string, not the token list\n",
    "\n",
    "# # CERTIFICATE NO. (TSR Number)\n",
    "# unique_identifier = data.get(\"cert_no\", \"\")  \n",
    "\n",
    "\n",
    "# # DATE\n",
    "# raw_date = data.get(\"calibration_date\", \"\")\n",
    "# # ensure a space between month name and day, then normalize commas and whitespace\n",
    "# step1 = re.sub(r\"([A-Za-z]+)(\\d)\", r\"\\1 \\2\", raw_date)\n",
    "# step2 = step1.replace(\",\", \", \")\n",
    "# norm  = re.sub(r\"\\s+\", \" \", step2).strip()\n",
    "\n",
    "# try:\n",
    "#     # parse “FullMonthName DD, YYYY” → “YYYY‑MM‑DD”\n",
    "#     dt = datetime.strptime(norm, \"%B %d, %Y\")\n",
    "#     begin_performance_date = dt.strftime(\"%Y-%m-%d\")\n",
    "# except ValueError:\n",
    "#     begin_performance_date = \"\"\n",
    "\n",
    "# end_performance_date   = \"\"\n",
    "\n",
    "# #PERFORMANCE LOCATION\n",
    "# performance_location   = \"LABORATORY\" #ONSITE or LABORATORY\n",
    "\n",
    "\n",
    "# # Calibration item\n",
    "# item_name             = data.get(\"calibration_item\", \"\")\n",
    "# equipment_ref_type    = \"\" \n",
    "# equipment_reference   = \"\" \n",
    "# equipment_class_id    = \"\"\n",
    "\n",
    "# #Standard item\n",
    "# subitem_name    = \"\"\n",
    "# subitem_model         = \"\"\n",
    "# ident_issuer          = \"\"\n",
    "# ident_value           = \"\"\n",
    "# ident_name            = \"\"\n",
    "\n",
    "# lab_code              = \"FORC\" #STATIC\n",
    "# lab_contact_name      = \"National Metrology Laboratory - Industrial Technology Development Institute\" #STATIC\n",
    "# lab_city              = \"Taguig\" #STATIC\n",
    "# lab_country_code      = \"PH\" #STATIC\n",
    "# lab_post_code         = \"1633\" #STATIC\n",
    "# lab_street            = \"General Santos Ave\" #STATIC\n",
    "\n",
    "# resp1_name            = \"\"\n",
    "# resp1_role            = \"\"\n",
    "# resp2_name            = \"\"\n",
    "# resp2_role            = \"\"\n",
    "# resp3_name            = \"\"\n",
    "# resp3_role            = \"\"\n",
    "\n",
    "# customer_name         = \"\"\n",
    "# customer_city         = \"\"\n",
    "# customer_country_code = \"PH\" #STATIC\n",
    "# customer_post_code    = \"\"\n",
    "# customer_street       = \"\"\n",
    "# customer_street_no    = \"\"\n",
    "\n",
    "# comment               = \"\"\n",
    "\n",
    "# # 2) parse + register namespaces\n",
    "# template = r\"valid xml\\empty.xml\"\n",
    "# output   = r\"valid xml\\filled.xml\"\n",
    "\n",
    "# ns = {\n",
    "#     \"dcc\": \"https://ptb.de/dcc\",\n",
    "#     \"si\":  \"https://ptb.de/si\"\n",
    "# }\n",
    "# for prefix, uri in ns.items():\n",
    "#     ET.register_namespace(prefix, uri)\n",
    "\n",
    "# tree = ET.parse(template)\n",
    "# root = tree.getroot()\n",
    "\n",
    "# def set_text(elem, txt, lang=None):\n",
    "#     if txt is None:\n",
    "#         return\n",
    "#     elem.text = txt\n",
    "#     if lang:\n",
    "#         elem.set(\"lang\", lang)\n",
    "\n",
    "# # 3) fill in\n",
    "# set_text(root.find(\".//dcc:software/dcc:name/dcc:content\", ns), software_name)\n",
    "# set_text(root.find(\".//dcc:software/dcc:release\",           ns), software_release)\n",
    "# set_text(root.find(\".//dcc:coreData/dcc:countryCodeISO3166_1\", ns), country_code_iso)\n",
    "# set_text(root.find(\".//dcc:coreData/dcc:usedLangCodeISO639_1\",  ns), used_lang_code)\n",
    "# set_text(root.find(\".//dcc:coreData/dcc:mandatoryLangCodeISO639_1\", ns), mandatory_lang_code)\n",
    "# set_text(root.find(\".//dcc:coreData/dcc:uniqueIdentifier\",       ns), unique_identifier)\n",
    "# set_text(root.find(\".//dcc:coreData/dcc:beginPerformanceDate\",   ns), begin_performance_date)\n",
    "# set_text(root.find(\".//dcc:coreData/dcc:endPerformanceDate\",     ns), end_performance_date)\n",
    "# set_text(root.find(\".//dcc:coreData/dcc:performanceLocation\",    ns), performance_location)\n",
    "\n",
    "# # items\n",
    "# set_text(root.find(\".//dcc:items/dcc:name/dcc:content\", ns), item_name, lang=used_lang_code)\n",
    "# ec = root.find(\".//dcc:items/dcc:equipmentClass\", ns)\n",
    "# if ec is not None:\n",
    "#     ec.set(\"refType\", equipment_ref_type)\n",
    "#     set_text(ec.find(\"dcc:reference\", ns), equipment_reference)\n",
    "#     set_text(ec.find(\"dcc:classID\",   ns), equipment_class_id)\n",
    "\n",
    "# # sub‐item + identification\n",
    "# si_el = root.find(\".//dcc:item\", ns)\n",
    "# if si_el is not None:\n",
    "#     set_text(si_el.find(\"dcc:name/dcc:content\", ns), subitem_name, lang=used_lang_code)\n",
    "#     set_text(si_el.find(\"dcc:model\", ns), subitem_model)\n",
    "#     ident = si_el.find(\"dcc:identifications/dcc:identification\", ns)\n",
    "#     if ident is not None:\n",
    "#         set_text(ident.find(\"dcc:issuer\",               ns), ident_issuer)\n",
    "#         set_text(ident.find(\"dcc:value\",                ns), ident_value)\n",
    "#         set_text(ident.find(\"dcc:name/dcc:content\",     ns), ident_name, lang=used_lang_code)\n",
    "\n",
    "# # laboratory\n",
    "# set_text(root.find(\".//dcc:calibrationLaboratory/dcc:calibrationLaboratoryCode\", ns), lab_code)\n",
    "# set_text(root.find(\".//dcc:calibrationLaboratory/dcc:contact/dcc:name/dcc:content\", ns), lab_contact_name, lang=used_lang_code)\n",
    "# set_text(root.find(\".//dcc:calibrationLaboratory/dcc:contact/dcc:location/dcc:city\",        ns), lab_city)\n",
    "# set_text(root.find(\".//dcc:calibrationLaboratory/dcc:contact/dcc:location/dcc:countryCode\",   ns), lab_country_code)\n",
    "# set_text(root.find(\".//dcc:calibrationLaboratory/dcc:contact/dcc:location/dcc:postCode\",     ns), lab_post_code)\n",
    "# set_text(root.find(\".//dcc:calibrationLaboratory/dcc:contact/dcc:location/dcc:street\",       ns), lab_street)\n",
    "\n",
    "# # respPersons\n",
    "# resp_nodes = root.findall(\".//dcc:respPersons/dcc:respPerson\", ns)\n",
    "# for idx, (name, role) in enumerate([\n",
    "#     (resp1_name, resp1_role),\n",
    "#     (resp2_name, resp2_role),\n",
    "#     (resp3_name, resp3_role),\n",
    "# ]):\n",
    "#     if idx < len(resp_nodes):\n",
    "#         rp = resp_nodes[idx]\n",
    "#         set_text(rp.find(\"dcc:person/dcc:name/dcc:content\", ns), name, lang=used_lang_code)\n",
    "#         set_text(rp.find(\"dcc:role\", ns), role)\n",
    "\n",
    "# # customer\n",
    "# cust = root.find(\".//dcc:customer\", ns)\n",
    "# if cust is not None:\n",
    "#     set_text(cust.find(\"dcc:name/dcc:content\", ns), customer_name, lang=used_lang_code)\n",
    "#     loc = cust.find(\"dcc:location\", ns)\n",
    "#     set_text(loc.find(\"dcc:city\", ns),        customer_city)\n",
    "#     set_text(loc.find(\"dcc:countryCode\", ns), customer_country_code)\n",
    "#     set_text(loc.find(\"dcc:postCode\", ns),    customer_post_code)\n",
    "#     set_text(loc.find(\"dcc:street\", ns),      customer_street)\n",
    "#     set_text(loc.find(\"dcc:streetNo\", ns),    customer_street_no)\n",
    "\n",
    "# # comment\n",
    "# set_text(root.find(\".//dcc:comment\", ns), comment)\n",
    "\n",
    "# # 4) write\n",
    "# tree.write(output, encoding=\"utf-8\", xml_declaration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06473ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xml.etree.ElementTree as ET\n",
    "\n",
    "# # 1) Declare one variable per tag (initially empty)\n",
    "# software_name            = \"Digital Calibration Certificate\"  # <dcc:name><dcc:content>\n",
    "# software_release         = \"1.0\"  # <dcc:release>\n",
    "# country_code_iso         = \"PHL\"  # <dcc:countryCodeISO3166_1>\n",
    "# used_lang_code           = \"en\"  # <dcc:usedLangCodeISO639_1>\n",
    "# mandatory_lang_code      = \"en\"  # <dcc:mandatoryLangCodeISO639_1>\n",
    "# unique_identifier        = \"01-2025-FORC-0013\"  # <dcc:uniqueIdentifier>\n",
    "# begin_performance_date   = \"2025-02-24\"  # <dcc:beginPerformanceDate>\n",
    "# end_performance_date     = \"\"  # <dcc:endPerformanceDate>\n",
    "# performance_location     = \"Marikina, Eastern Manila District, NCR\"  # <dcc:performanceLocation>\n",
    "\n",
    "# item_name                = \"Axle Weighing Scale\"  # <dcc:items>/<dcc:name>/<dcc:content>\n",
    "# equipment_ref_type       = \"instrument\"  # equipmentClass refType=\n",
    "# equipment_reference      = \"APOLLO / AW565\"  # <dcc:equipmentClass>/<dcc:reference>\n",
    "# equipment_class_id       = \"weighing_scale\"  # <dcc:equipmentClass>/<dcc:classID>\n",
    "\n",
    "# subitem_name             = \"Axle Weighing Scale\"  # <dcc:item>/<dcc:name>/<dcc:content>\n",
    "# subitem_model            = \"APOLLO / AW565\"  # <dcc:item>/<dcc:model>\n",
    "# ident_issuer             = \"Manufacturer\"  # <dcc:identification>/<dcc:issuer>\n",
    "# ident_value              = \"A386856\"  # <dcc:identification>/<dcc:value>\n",
    "# ident_name               = \"Serial Number\"  # <dcc:identification>/<dcc:name>/<dcc:content>\n",
    "\n",
    "# lab_code                 = \"NMD-ITDI\"  # <dcc:calibrationLaboratoryCode>\n",
    "# lab_contact_name         = \"National Metrology Laboratory\"  # <dcc:contact>/<dcc:name>/<dcc:content>\n",
    "# lab_city                 = \"Manila\"  # <dcc:location>/<dcc:city>\n",
    "# lab_country_code         = \"PHL\"  # <dcc:location>/<dcc:countryCode>\n",
    "# lab_post_code            = \"\"  # <dcc:location>/<dcc:postCode>\n",
    "# lab_street               = \"\"  # <dcc:location>/<dcc:street>\n",
    "\n",
    "# resp1_name               = \"AHDRIAN CAMILO C. GERNALE\"  # first <dcc:respPerson>/<dcc:person>/<dcc:name>/<dcc:content>\n",
    "# resp1_role               = \"Science Research Specialist II\"  # first <dcc:respPerson>/<dcc:role>\n",
    "# resp2_name               = \"RADLEY F. MANALO\"  # second respPerson...\n",
    "# resp2_role               = \"Senior Science Research Specialist\"\n",
    "# resp3_name               = \"MARYNESS I. SALAZAR, PhD\"  # third respPerson...\n",
    "# resp3_role               = \"Head, Pressure and Force Standards Section\"\n",
    "\n",
    "# customer_name            = \"\"  # <dcc:customer>/<dcc:name>/<dcc:content>\n",
    "# customer_city            = \"Marikina\"  # <dcc:customer>/<dcc:location>/<dcc:city>\n",
    "# customer_country_code    = \"PHL\"  # <…>/countryCode\n",
    "# customer_post_code       = \"\"  # <…>/postCode\n",
    "# customer_street          = \"No. 4 Malaya Street Malanday\"  # <…>/street\n",
    "# customer_street_no       = \"4\"  # <…>/streetNo\n",
    "\n",
    "# comment                  = \"The axle weighing scale was calibrated in static compression mode.\"  # <dcc:comment>\n",
    "\n",
    "# # 2) Parse template and inject\n",
    "# template_path = r\"valid xml\\empty.xml\"\n",
    "# output_path   = r\"valid xml\\filled.xml\"\n",
    "\n",
    "# ns = {\n",
    "#     \"dcc\": \"https://ptb.de/dcc\",\n",
    "#     \"si\":  \"https://ptb.de/si\"\n",
    "# }\n",
    "\n",
    "# # register your prefixes so ET will reuse them instead of ns0, ns1…\n",
    "# for prefix, uri in ns.items():\n",
    "#     ET.register_namespace(prefix, uri)\n",
    "\n",
    "# tree = ET.parse(template_path)\n",
    "# root = tree.getroot()\n",
    "\n",
    "# def set_text(path, value):\n",
    "#     el = root.find(path, ns)\n",
    "#     if el is not None:\n",
    "#         el.text = value\n",
    "        \n",
    "\n",
    "# set_text(\".//dcc:software/dcc:name/dcc:content\", software_name)\n",
    "# set_text(\".//dcc:software/dcc:release\", software_release)\n",
    "# set_text(\".//dcc:coreData/dcc:countryCodeISO3166_1\", country_code_iso)\n",
    "# set_text(\".//dcc:coreData/dcc:usedLangCodeISO639_1\", used_lang_code)\n",
    "# set_text(\".//dcc:coreData/dcc:mandatoryLangCodeISO639_1\", mandatory_lang_code)\n",
    "# set_text(\".//dcc:coreData/dcc:uniqueIdentifier\", unique_identifier)\n",
    "# set_text(\".//dcc:coreData/dcc:beginPerformanceDate\", begin_performance_date)\n",
    "# set_text(\".//dcc:coreData/dcc:endPerformanceDate\", end_performance_date)\n",
    "# set_text(\".//dcc:coreData/dcc:performanceLocation\", performance_location)\n",
    "\n",
    "# set_text(\".//dcc:items/dcc:name/dcc:content\", item_name)\n",
    "# set_text(\".//dcc:items/dcc:equipmentClass\", equipment_ref_type)        # via attribute\n",
    "# set_text(\".//dcc:items/dcc:equipmentClass/dcc:reference\", equipment_reference)\n",
    "# set_text(\".//dcc:items/dcc:equipmentClass/dcc:classID\", equipment_class_id)\n",
    "\n",
    "# set_text(\".//dcc:item/dcc:name/dcc:content\", subitem_name)\n",
    "# set_text(\".//dcc:item/dcc:model\", subitem_model)\n",
    "# set_text(\".//dcc:identification/dcc:issuer\", ident_issuer)\n",
    "# set_text(\".//dcc:identification/dcc:value\", ident_value)\n",
    "# set_text(\".//dcc:identification/dcc:name/dcc:content\", ident_name)\n",
    "\n",
    "# set_text(\".//dcc:calibrationLaboratory/dcc:calibrationLaboratoryCode\", lab_code)\n",
    "# set_text(\".//dcc:calibrationLaboratory/dcc:contact/dcc:name/dcc:content\", lab_contact_name)\n",
    "# set_text(\".//dcc:calibrationLaboratory/dcc:contact/dcc:location/dcc:city\", lab_city)\n",
    "# set_text(\".//dcc:calibrationLaboratory/dcc:contact/dcc:location/dcc:countryCode\", lab_country_code)\n",
    "# set_text(\".//dcc:calibrationLaboratory/dcc:contact/dcc:location/dcc:postCode\", lab_post_code)\n",
    "# set_text(\".//dcc:calibrationLaboratory/dcc:contact/dcc:location/dcc:street\", lab_street)\n",
    "\n",
    "# set_text(\".//dcc:respPersons/dcc:respPerson[1]/dcc:person/dcc:name/dcc:content\", resp1_name)\n",
    "# set_text(\".//dcc:respPersons/dcc:respPerson[1]/dcc:role\", resp1_role)\n",
    "# set_text(\".//dcc:respPersons/dcc:respPerson[2]/dcc:person/dcc:name/dcc:content\", resp2_name)\n",
    "# set_text(\".//dcc:respPersons/dcc:respPerson[2]/dcc:role\", resp2_role)\n",
    "# set_text(\".//dcc:respPersons/dcc:respPerson[3]/dcc:person/dcc:name/dcc:content\", resp3_name)\n",
    "# set_text(\".//dcc:respPersons/dcc:respPerson[3]/dcc:role\", resp3_role)\n",
    "\n",
    "# set_text(\".//dcc:customer/dcc:name/dcc:content\", customer_name)\n",
    "# set_text(\".//dcc:customer/dcc:location/dcc:city\", customer_city)\n",
    "# set_text(\".//dcc:customer/dcc:location/dcc:countryCode\", customer_country_code)\n",
    "# set_text(\".//dcc:customer/dcc:location/dcc:postCode\", customer_post_code)\n",
    "# set_text(\".//dcc:customer/dcc:location/dcc:street\", customer_street)\n",
    "# set_text(\".//dcc:customer/dcc:location/dcc:streetNo\", customer_street_no)\n",
    "\n",
    "# set_text(\".//dcc:comment\", comment)\n",
    "\n",
    "# # 3) Write out your filled XML\n",
    "# tree.write(output_path, encoding=\"utf-8\", xml_declaration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d4a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 2 pages from TISSI-sample-certificate.pdf...\n",
      "Finished extracting text.\n",
      "Attempting to extract data fields...\n",
      "Info: Inferred language codes 'en' based on document language.\n",
      "Warning: Could not find 'STANDARD USED' section.\n",
      "Warning: Could not find measurement results table header.\n",
      "Finished extracting data fields.\n",
      "Final data keys to be used for XML: ['uniqueIdentifier', 'usedLangCodeISO639_1', 'mandatoryLangCodeISO639_1', 'item_name', 'item_serial_number', 'calibrationLaboratoryCode', 'respPerson1_name', 'respPerson1_role', 'respPerson3_name', 'respPerson3_role', 'customer_street', 'customer_city', 'measurement_table']\n",
      "Creating XML file at output_dcc_strict.xml...\n",
      "Successfully created pretty XML file: output_dcc_strict.xml\n"
     ]
    }
   ],
   "source": [
    "# # Install necessary libraries:\n",
    "# # pip install PyPDF2\n",
    "\n",
    "# import PyPDF2\n",
    "# import re\n",
    "# import xml.etree.ElementTree as ET\n",
    "# from xml.dom import minidom # For pretty printing XML\n",
    "# import datetime # For date parsing\n",
    "\n",
    "# # --- Helper Functions ---\n",
    "\n",
    "# def extract_text_from_pdf(pdf_path):\n",
    "#     \"\"\"Extracts text content from all pages of a PDF file.\"\"\"\n",
    "#     text = \"\"\n",
    "#     try:\n",
    "#         # It's crucial to ensure the PDF path is correct and accessible\n",
    "#         with open(pdf_path, 'rb') as pdf_file:\n",
    "#             reader = PyPDF2.PdfReader(pdf_file)\n",
    "#             num_pages = len(reader.pages)\n",
    "#             print(f\"Reading {num_pages} pages from {pdf_path}...\")\n",
    "#             for page_num in range(num_pages):\n",
    "#                 page = reader.pages[page_num]\n",
    "#                 # Extract text using PyPDF2\n",
    "#                 page_text = page.extract_text()\n",
    "#                 if page_text:\n",
    "#                     text += page_text + \"\\n\\n\" # Add double newline between pages for separation\n",
    "#                 else:\n",
    "#                     print(f\"Warning: Could not extract text from page {page_num + 1}.\")\n",
    "#         print(\"Finished extracting text.\")\n",
    "#         # Basic cleaning: replace multiple spaces/newlines which can affect regex\n",
    "#         text = re.sub(r'\\s{2,}', ' ', text) # Replace multiple spaces with one\n",
    "#         text = re.sub(r'\\n+', '\\n', text)   # Replace multiple newlines with one\n",
    "#         return text\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: PDF file not found at '{pdf_path}'\")\n",
    "#         return None\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred during PDF reading: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def find_pattern(text, pattern, label=\"pattern\", group=1, default=None, flags=re.IGNORECASE | re.MULTILINE):\n",
    "#     \"\"\"Uses regex to find a pattern and returns the specified capturing group or default.\"\"\"\n",
    "#     if not text:\n",
    "#         return default\n",
    "#     try:\n",
    "#         match = re.search(pattern, text, flags)\n",
    "#         if match:\n",
    "#             try:\n",
    "#                 # Return the specified capturing group, stripping whitespace\n",
    "#                 return match.group(group).strip()\n",
    "#             except IndexError:\n",
    "#                 # Only print warning if label is provided\n",
    "#                 if label:\n",
    "#                     print(f\"Warning: Regex pattern for '{label}' matched, but group {group} not found.\")\n",
    "#                 return default\n",
    "#             except Exception as e:\n",
    "#                  # Only print warning if label is provided\n",
    "#                  if label:\n",
    "#                      print(f\"Warning: Error accessing group {group} for '{label}': {e}\")\n",
    "#                  return default\n",
    "#         else:\n",
    "#             # Only print warning if label is provided and pattern wasn't found\n",
    "#             # if label:\n",
    "#             #     print(f\"Debug: Could not find {label} using pattern: {pattern}\") # Less verbose\n",
    "#             return default\n",
    "#     except Exception as e:\n",
    "#         # Only print warning if label is provided\n",
    "#         if label:\n",
    "#             print(f\"An error occurred during regex search for '{label}': {e}\")\n",
    "#         return default\n",
    "\n",
    "# def parse_date(date_str, label=\"date\"):\n",
    "#     \"\"\"Parses common date formats and returns YYYY-MM-DD.\"\"\"\n",
    "#     if not date_str:\n",
    "#         return None\n",
    "#     try:\n",
    "#         # Example: \"February 24, 2025\"\n",
    "#         dt_object = datetime.datetime.strptime(date_str.strip(), \"%B %d, %Y\")\n",
    "#         return dt_object.strftime(\"%Y-%m-%d\")\n",
    "#     except ValueError:\n",
    "#         print(f\"Warning: Could not parse {label} string '{date_str}' into YYYY-MM-DD format.\")\n",
    "#         return None\n",
    "\n",
    "# def extract_table_data(text):\n",
    "#     \"\"\"\n",
    "#     Extracts data from the measurement results table.\n",
    "#     NOTE: This is highly dependent on the text extraction format and spacing.\n",
    "#           This is FRAGILE and might need a more robust PDF table parsing library.\n",
    "#     \"\"\"\n",
    "#     table_data = {\n",
    "#         \"Applied Force\": [],\n",
    "#         \"Indicated Force\": [],\n",
    "#         \"Deviation\": [],\n",
    "#         \"Relative Expanded Uncertainty\": [],\n",
    "#         \"Relative Accuracy Error\": [],\n",
    "#     }\n",
    "#     if not text:\n",
    "#         return table_data\n",
    "\n",
    "#     # Try to find the start of the table data rows (after the header)\n",
    "#     header_match = re.search(r\"Applied\\s+Force\\s+Indicated\\s+Force.*?Error\\s*kgf\\s+kgf\\s+kgf\\s+%\\s+%\", text, re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "#     if not header_match:\n",
    "#         print(\"Warning: Could not find measurement results table header.\")\n",
    "#         return table_data # Return empty dict if header not found\n",
    "\n",
    "#     # Extract text *after* the header\n",
    "#     table_content = text[header_match.end():]\n",
    "\n",
    "#     # Find the end of the table (e.g., start of \"UNCERTAINTY OF MEASUREMENT\")\n",
    "#     end_match = re.search(r\"UNCERTAINTY OF MEASUREMENT\", table_content, re.IGNORECASE)\n",
    "#     if end_match:\n",
    "#         table_content = table_content[:end_match.start()]\n",
    "\n",
    "#     # Split into lines and process rows containing numerical data\n",
    "#     lines = table_content.strip().split('\\n')\n",
    "#     # Regex to capture the 5 columns, allowing for spaces within numbers (like \"2 900\") and negative signs\n",
    "#     row_pattern = re.compile(r\"^\\s*([\\d\\.\\-]+)\\s+([\\d\\s\\.\\-]+)\\s+([\\d\\.\\-]+)\\s+([\\d\\.]+)\\s+([\\d\\.]+)\\s*$\")\n",
    "\n",
    "#     found_rows = 0\n",
    "#     for line in lines:\n",
    "#         line = line.strip()\n",
    "#         # Clean up potential issues like \"2 900\" -> \"2900\" before matching\n",
    "#         cleaned_line = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', line)\n",
    "#         # Handle potential negative sign separated by space like \"- 50\" -> \"-50\"\n",
    "#         cleaned_line = re.sub(r'-\\s+(\\d)', r'-\\1', cleaned_line)\n",
    "\n",
    "#         match = row_pattern.match(cleaned_line)\n",
    "#         if match:\n",
    "#             try:\n",
    "#                 # Further clean spaces from matched groups if necessary (though sub above should handle most)\n",
    "#                 table_data[\"Applied Force\"].append(match.group(1).replace(\" \", \"\"))\n",
    "#                 table_data[\"Indicated Force\"].append(match.group(2).replace(\" \", \"\"))\n",
    "#                 table_data[\"Deviation\"].append(match.group(3).replace(\" \", \"\"))\n",
    "#                 table_data[\"Relative Expanded Uncertainty\"].append(match.group(4).replace(\" \", \"\"))\n",
    "#                 table_data[\"Relative Accuracy Error\"].append(match.group(5).replace(\" \", \"\"))\n",
    "#                 found_rows += 1\n",
    "#             except IndexError:\n",
    "#                 print(f\"Warning: Could not parse all columns from table row: {line}\")\n",
    "#         # else:\n",
    "#             # print(f\"Debug: Line did not match table row pattern: '{line}' (cleaned: '{cleaned_line}')\") # Uncomment for debugging\n",
    "\n",
    "#     if found_rows == 0:\n",
    "#          print(\"Warning: Failed to extract any numerical data rows from the table.\")\n",
    "#          return {} # Return empty dict if no rows parsed\n",
    "#     else:\n",
    "#          print(f\"Successfully extracted {found_rows} rows of table data.\")\n",
    "#          # print(\"Table Data:\", table_data) # Uncomment for debugging\n",
    "\n",
    "#     return table_data\n",
    "\n",
    "# # --- Main Data Extraction Function ---\n",
    "\n",
    "# def extract_calibration_data(text):\n",
    "#     \"\"\"\n",
    "#     Extracts specific data points from the text using regex.\n",
    "#     Only stores data explicitly found in the text.\n",
    "#     \"\"\"\n",
    "#     if not text:\n",
    "#         return None\n",
    "\n",
    "#     data = {}\n",
    "#     print(\"Attempting to extract data fields...\")\n",
    "\n",
    "#     # --- Administrative Data ---\n",
    "#     # Use find_pattern which returns None if not found\n",
    "#     data['uniqueIdentifier'] = find_pattern(text, r\"No\\.\\s+([0-9\\-A-Z]+)\", \"Unique Identifier\")\n",
    "#     raw_date = find_pattern(text, r\"Date of Calibration\\s*:\\s*([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})\", \"Calibration Date String\")\n",
    "#     data['calibrationDate'] = parse_date(raw_date, \"Calibration Date\")\n",
    "#     # Performance dates often same as calibration date, assign if calibration date found\n",
    "#     if data['calibrationDate']:\n",
    "#         data['beginPerformanceDate'] = data['calibrationDate']\n",
    "#         data['endPerformanceDate'] = data['calibrationDate']\n",
    "#     # Performance location is not explicitly stated in the sample PDF\n",
    "#     # data['performanceLocation'] = find_pattern(text, r\"Location:\\s*(.+)\", \"Performance Location\") # Example if pattern existed\n",
    "\n",
    "#     # Country/Language codes inferred from context (document language, addresses)\n",
    "#     # Only include if reasonably certain from context, otherwise omit.\n",
    "#     # Checking for NCR in address implies PH.\n",
    "#     if find_pattern(text, r\"NCR\", label=None): # Check if NCR is mentioned\n",
    "#          data['countryCodeISO3166_1'] = \"PH\" # Inferred\n",
    "#          print(\"Info: Inferred country code 'PH' based on context (NCR mention).\")\n",
    "#     data['usedLangCodeISO639_1'] = \"en\" # Inferred from document language\n",
    "#     data['mandatoryLangCodeISO639_1'] = \"en\" # Inferred from document language\n",
    "#     print(\"Info: Inferred language codes 'en' based on document language.\")\n",
    "\n",
    "\n",
    "#     # --- Item Information ---\n",
    "#     data['item_name'] = find_pattern(text, r\"Calibration Item\\s*:\\s*(.+?)\\s*(?:Capacity|Measurement Range|Make/Model)\", \"Item Name\")\n",
    "#     data['item_model'] = find_pattern(text, r\"Make/Model\\s*:\\s*([^;\\n]+)\", \"Item Model\") # Stop at semicolon or newline\n",
    "#     data['item_serial_number'] = find_pattern(text, r\"Serial No\\.\\s*:\\s*(\\S+)\", \"Item Serial Number\")\n",
    "\n",
    "#     # --- Standard Used (Equipment Class) ---\n",
    "#     standard_section_match = re.search(r\"STANDARD USED:(.*?)(CALIBRATION PROCEDURE:|ENVIRONMENTAL CONDITIONS:)\", text, re.IGNORECASE | re.DOTALL)\n",
    "#     standard_text = standard_section_match.group(1) if standard_section_match else \"\"\n",
    "#     if standard_text:\n",
    "#         data['standard_ref_sn'] = find_pattern(standard_text, r\"SN\\s+(\\S+)\", \"Standard SN\")\n",
    "#         raw_standard_model = find_pattern(standard_text, r\"Shimadzu/\\s*(UH-?F1000kNX)\", \"Standard Model\") # Handle optional hyphen\n",
    "#         if raw_standard_model:\n",
    "#              # Clean up standard model if found\n",
    "#              data['standard_model'] = raw_standard_model.replace('-', '')\n",
    "#     else:\n",
    "#         print(\"Warning: Could not find 'STANDARD USED' section.\")\n",
    "\n",
    "\n",
    "#     # --- Calibration Laboratory ---\n",
    "#     # Extract lab code from identifier if possible and found\n",
    "#     if data.get('uniqueIdentifier'):\n",
    "#         match = re.search(r'-([A-Z]+)-', data['uniqueIdentifier'])\n",
    "#         if match:\n",
    "#             data['calibrationLaboratoryCode'] = match.group(1)\n",
    "#         else:\n",
    "#              print(\"Warning: Could not extract laboratory code from unique identifier.\")\n",
    "#     # Lab name: Look for explicit mention or specific context line\n",
    "#     # The line \"For the Chief...\" is context, not the actual lab name. Look for NML-ITDI explicitly.\n",
    "#     data['lab_name'] = find_pattern(text, r\"(NML-ITDI)\", \"Lab Name Explicit\")\n",
    "#     if not data.get('lab_name'):\n",
    "#          # Fallback: Check if standard traceability mentions it\n",
    "#          data['lab_name'] = find_pattern(standard_text, r\"NMD-ITDI\", \"Lab Name from Standard Traceability\")\n",
    "\n",
    "#     # Lab location details are not present in the sample PDF text. Do not add.\n",
    "\n",
    "\n",
    "#     # --- Responsible Persons ---\n",
    "#     # Use find_pattern which returns None if not found\n",
    "#     data['respPerson1_name'] = find_pattern(text, r\"(AHDRIAN CAMILO C\\. GERNALE)\\s+Science Research Specialist II\", \"Resp Person 1 Name\")\n",
    "#     if data.get('respPerson1_name'): data['respPerson1_role'] = \"Science Research Specialist II\"\n",
    "\n",
    "#     data['respPerson2_name'] = find_pattern(text, r\"(RADLEY F\\. MANALO)\\s+Senior Science Research Specialist\", \"Resp Person 2 Name\")\n",
    "#     if data.get('respPerson2_name'): data['respPerson2_role'] = \"Senior Science Research Specialist\"\n",
    "\n",
    "#     # Person 3 name has comma, need to be careful with regex if matching role on same line\n",
    "#     # Match name first, then look for role nearby if needed\n",
    "#     data['respPerson3_name'] = find_pattern(text, r\"(MARYNESS I\\. SALAZAR, PhD)\", \"Resp Person 3 Name\")\n",
    "#     if data.get('respPerson3_name'):\n",
    "#         # Check if role follows immediately or on next line (adjust pattern if needed)\n",
    "#         role3_match = re.search(re.escape(data['respPerson3_name']) + r\"\\s+(Head, Pressure and Force Standards Section)\", text)\n",
    "#         if role3_match:\n",
    "#             data['respPerson3_role'] = role3_match.group(1).strip()\n",
    "#         else:\n",
    "#             # Try looking for the role on its own line if structure varies\n",
    "#             data['respPerson3_role'] = find_pattern(text, r\"Head, Pressure and Force Standards Section\", \"Resp Person 3 Role\")\n",
    "\n",
    "\n",
    "#     # --- Customer ---\n",
    "#     data['customer_name'] = find_pattern(text, r\"Customer\\s*:\\s*(.+?)\\s*(?:No\\.|MEASUREMENT RESULTS)\", \"Customer Name\")\n",
    "#     # Extract address lines more carefully\n",
    "#     customer_block_match = re.search(r\"Customer\\s*:\\s*.+?\\n\\s*(.+?)\\n\\s*(.+?)(?:\\n|$)\", text, re.IGNORECASE)\n",
    "#     if customer_block_match:\n",
    "#         addr_line1 = customer_block_match.group(1).strip()\n",
    "#         addr_line2 = customer_block_match.group(2).strip()\n",
    "\n",
    "#         # Try to parse Street No, Street from line 1\n",
    "#         street_no_match = re.match(r\"(No\\.\\s*\\d+)\\s*(.*)\", addr_line1)\n",
    "#         if street_no_match:\n",
    "#             data['customer_streetNo'] = street_no_match.group(1)\n",
    "#             data['customer_street'] = street_no_match.group(2)\n",
    "#         else:\n",
    "#             # If no \"No.\" prefix, assume the whole line is the street\n",
    "#             data['customer_street'] = addr_line1\n",
    "\n",
    "#         # Try to parse City from line 2 (usually before comma or end of line)\n",
    "#         city_match = re.match(r\"([^,]+)\", addr_line2)\n",
    "#         if city_match:\n",
    "#             data['customer_city'] = city_match.group(1).strip()\n",
    "\n",
    "#         # Post code is not present in the address lines in the PDF text. Do not add.\n",
    "#         # data['customer_postCode'] = find_pattern(addr_line2, r\"(\\d{4})\", \"Customer Postcode\") # Example if it existed\n",
    "\n",
    "#     # Customer country code inferred from context (NCR mention)\n",
    "#     if data.get('countryCodeISO3166_1'): # Use lab's inferred country code if available\n",
    "#          data['customer_countryCode'] = data['countryCodeISO3166_1']\n",
    "\n",
    "\n",
    "#     # --- Measurement Results Table ---\n",
    "#     data['measurement_table'] = extract_table_data(text)\n",
    "\n",
    "#     print(\"Finished extracting data fields.\")\n",
    "#     # Remove keys with None values before returning for cleaner XML generation check\n",
    "#     cleaned_data = {k: v for k, v in data.items() if v is not None and v != \"\"}\n",
    "#     # Special check for table data - keep if not empty dict\n",
    "#     if 'measurement_table' in data and data['measurement_table']:\n",
    "#          cleaned_data['measurement_table'] = data['measurement_table']\n",
    "#     elif 'measurement_table' in cleaned_data: # remove if it ended up empty\n",
    "#          del cleaned_data['measurement_table']\n",
    "\n",
    "\n",
    "#     print(\"Final data keys to be used for XML:\", list(cleaned_data.keys()))\n",
    "#     return cleaned_data\n",
    "\n",
    "\n",
    "# # --- XML Generation Function ---\n",
    "\n",
    "# def create_dcc_xml(data, output_xml_path):\n",
    "#     \"\"\"\n",
    "#     Creates a DCC XML file based *only* on the extracted data provided.\n",
    "#     Checks for key existence before adding elements.\n",
    "#     \"\"\"\n",
    "#     if not data:\n",
    "#         print(\"Error: No valid data extracted to create XML.\")\n",
    "#         return\n",
    "\n",
    "#     print(f\"Creating XML file at {output_xml_path}...\")\n",
    "\n",
    "#     # --- Define Namespaces ---\n",
    "#     NS_DCC = \"https://ptb.de/dcc\"\n",
    "#     NS_SI = \"https://ptb.de/si\"\n",
    "#     NS_XSI = \"http://www.w3.org/2001/XMLSchema-instance\"\n",
    "#     ET.register_namespace('dcc', NS_DCC)\n",
    "#     ET.register_namespace('si', NS_SI)\n",
    "#     ET.register_namespace('xsi', NS_XSI)\n",
    "\n",
    "#     # --- Root Element ---\n",
    "#     root = ET.Element(f\"{{{NS_DCC}}}digitalCalibrationCertificate\",\n",
    "#                       attrib={\n",
    "#                           f\"{{{NS_XSI}}}schemaLocation\": f\"{NS_DCC} https://ptb.de/dcc/v3.2.1/dcc.xsd\",\n",
    "#                           \"schemaVersion\": \"3.2.1\" # Schema version is required by schemaLocation\n",
    "#                       })\n",
    "\n",
    "#     # --- Helper to create namespaced elements with text ---\n",
    "#     def create_element(parent, ns, tag, text=None, attrib=None):\n",
    "#         # Only create element if parent exists and (text is valid or it's meant to be a container)\n",
    "#         if parent is not None and (text is not None or attrib is not None):\n",
    "#              element = ET.SubElement(parent, f\"{{{ns}}}{tag}\", attrib=attrib if attrib else {})\n",
    "#              if text is not None:\n",
    "#                  element.text = str(text)\n",
    "#              return element\n",
    "#         return None # Return None if parent is None or no text/attributes provided\n",
    "\n",
    "#     # --- Helper to create dcc:content elements ---\n",
    "#     def create_dcc_content(parent, ns, tag, content_text, lang=\"en\"):\n",
    "#          if content_text and parent is not None: # Check both content and parent\n",
    "#              name_elem = ET.SubElement(parent, f\"{{{ns}}}{tag}\")\n",
    "#              content_elem = ET.SubElement(name_elem, f\"{{{ns}}}content\", attrib={\"lang\": lang})\n",
    "#              content_elem.text = str(content_text)\n",
    "#              return name_elem\n",
    "#          return None\n",
    "\n",
    "#     # --- Administrative Data ---\n",
    "#     admin_data = create_element(root, NS_DCC, \"administrativeData\") # Create main container\n",
    "\n",
    "#     # Software Info (Optional - Example shows it, but not from PDF)\n",
    "#     # If you want to include this, uncomment the following lines.\n",
    "#     # dcc_software = create_element(admin_data, NS_DCC, \"dccSoftware\")\n",
    "#     # if dcc_software is not None:\n",
    "#     #     software = create_element(dcc_software, NS_DCC, \"software\")\n",
    "#     #     if software is not None:\n",
    "#     #         create_dcc_content(software, NS_DCC, \"name\", \"Python DCC Generator\") # Example name\n",
    "#     #         create_element(software, NS_DCC, \"release\", \"1.1\") # Example release\n",
    "\n",
    "#     # Core Data - Create container only if there's core data to add\n",
    "#     core_data_items = {\n",
    "#         'countryCodeISO3166_1': data.get('countryCodeISO3166_1'),\n",
    "#         'usedLangCodeISO639_1': data.get('usedLangCodeISO639_1'),\n",
    "#         'mandatoryLangCodeISO639_1': data.get('mandatoryLangCodeISO639_1'),\n",
    "#         'uniqueIdentifier': data.get('uniqueIdentifier'),\n",
    "#         'beginPerformanceDate': data.get('beginPerformanceDate'),\n",
    "#         'endPerformanceDate': data.get('endPerformanceDate'),\n",
    "#         'performanceLocation': data.get('performanceLocation') # Will likely be None\n",
    "#     }\n",
    "#     # Filter out None values\n",
    "#     valid_core_data = {k: v for k, v in core_data_items.items() if v is not None}\n",
    "#     if valid_core_data:\n",
    "#         core_data = create_element(admin_data, NS_DCC, \"coreData\")\n",
    "#         for key, value in valid_core_data.items():\n",
    "#             create_element(core_data, NS_DCC, key, value) # Use dict key as tag name\n",
    "\n",
    "#     # Items - Create container only if item name or details exist\n",
    "#     if data.get('item_name') or data.get('standard_ref_sn') or data.get('standard_model') or data.get('item_model') or data.get('item_serial_number'):\n",
    "#         items = create_element(admin_data, NS_DCC, \"items\")\n",
    "#         create_dcc_content(items, NS_DCC, \"name\", data.get('item_name'))\n",
    "\n",
    "#         # Equipment Class (Standard Used) - Create only if standard data exists\n",
    "#         if data.get('standard_ref_sn') or data.get('standard_model'):\n",
    "#             equip_class = create_element(items, NS_DCC, \"equipmentClass\", attrib={\"refType\": \"Force Measuring Instrument\"})\n",
    "#             if equip_class is not None:\n",
    "#                 create_element(equip_class, NS_DCC, \"reference\", data.get('standard_ref_sn'))\n",
    "#                 create_element(equip_class, NS_DCC, \"classID\", data.get('standard_model'))\n",
    "\n",
    "#         # Item Details - Create container only if model or serial number exists\n",
    "#         if data.get('item_model') or data.get('item_serial_number'):\n",
    "#             item = create_element(items, NS_DCC, \"item\")\n",
    "#             if item is not None:\n",
    "#                 create_dcc_content(item, NS_DCC, \"name\", data.get('item_name')) # Repeat item name inside item\n",
    "#                 create_element(item, NS_DCC, \"model\", data.get('item_model'))\n",
    "\n",
    "#                 # Identifications (Serial Number) - Create only if serial number exists\n",
    "#                 if data.get('item_serial_number'):\n",
    "#                     identifications = create_element(item, NS_DCC, \"identifications\")\n",
    "#                     if identifications is not None:\n",
    "#                         identification = create_element(identifications, NS_DCC, \"identification\")\n",
    "#                         if identification is not None:\n",
    "#                             create_element(identification, NS_DCC, \"issuer\", \"customer\") # Assumption\n",
    "#                             create_element(identification, NS_DCC, \"value\", data.get('item_serial_number'))\n",
    "#                             create_dcc_content(identification, NS_DCC, \"name\", data.get('item_model')) # Use model as name\n",
    "\n",
    "#     # Calibration Laboratory - Create only if code or contact info exists\n",
    "#     if data.get('calibrationLaboratoryCode') or data.get('lab_name'):\n",
    "#         calib_lab = create_element(admin_data, NS_DCC, \"calibrationLaboratory\")\n",
    "#         if calib_lab is not None:\n",
    "#             create_element(calib_lab, NS_DCC, \"calibrationLaboratoryCode\", data.get('calibrationLaboratoryCode'))\n",
    "#             # Contact - Create only if name or location details exist (name is likely only one found)\n",
    "#             if data.get('lab_name'): # Add other conditions if lab location fields were added back\n",
    "#                 contact = create_element(calib_lab, NS_DCC, \"contact\")\n",
    "#                 if contact is not None:\n",
    "#                     create_dcc_content(contact, NS_DCC, \"name\", data.get('lab_name'))\n",
    "#                     # Location - Create only if location details exist (unlikely for lab in this PDF)\n",
    "#                     # lab_location_data = {k: data.get(f\"lab_{k}\") for k in [\"city\", \"countryCode\", \"postCode\", \"street\"] if data.get(f\"lab_{k}\")}\n",
    "#                     # if lab_location_data:\n",
    "#                     #    location = create_element(contact, NS_DCC, \"location\")\n",
    "#                     #    for key, value in lab_location_data.items():\n",
    "#                     #        create_element(location, NS_DCC, key, value)\n",
    "\n",
    "#     # Responsible Persons - Create container only if at least one person found\n",
    "#     resp_persons_data = []\n",
    "#     for i in range(1, 4):\n",
    "#         name_key = f'respPerson{i}_name'\n",
    "#         role_key = f'respPerson{i}_role'\n",
    "#         if data.get(name_key) and data.get(role_key):\n",
    "#             resp_persons_data.append({'name': data[name_key], 'role': data[role_key]})\n",
    "\n",
    "#     if resp_persons_data:\n",
    "#         resp_persons = create_element(admin_data, NS_DCC, \"respPersons\")\n",
    "#         if resp_persons is not None:\n",
    "#             for person_data in resp_persons_data:\n",
    "#                 resp_person = create_element(resp_persons, NS_DCC, \"respPerson\")\n",
    "#                 if resp_person is not None:\n",
    "#                     person = create_element(resp_person, NS_DCC, \"person\")\n",
    "#                     if person is not None:\n",
    "#                         create_dcc_content(person, NS_DCC, \"name\", person_data['name'])\n",
    "#                     create_element(resp_person, NS_DCC, \"role\", person_data['role'])\n",
    "\n",
    "#     # Customer - Create container only if name or location details exist\n",
    "#     cust_location_data = {k: data.get(f\"customer_{k}\") for k in [\"city\", \"countryCode\", \"postCode\", \"street\", \"streetNo\"] if data.get(f\"customer_{k}\")}\n",
    "#     if data.get('customer_name') or cust_location_data:\n",
    "#          customer = create_element(admin_data, NS_DCC, \"customer\")\n",
    "#          if customer is not None:\n",
    "#              create_dcc_content(customer, NS_DCC, \"name\", data.get('customer_name'))\n",
    "#              # Location - Create only if location details exist\n",
    "#              if cust_location_data:\n",
    "#                  cust_location = create_element(customer, NS_DCC, \"location\")\n",
    "#                  if cust_location is not None:\n",
    "#                     # Map dict keys back to XML tags (handle streetNo case)\n",
    "#                     tag_map = {\"city\": \"city\", \"countryCode\": \"countryCode\", \"postCode\": \"postCode\", \"street\": \"street\", \"streetNo\": \"streetNo\"}\n",
    "#                     for key, value in cust_location_data.items():\n",
    "#                         create_element(cust_location, NS_DCC, tag_map[key], value)\n",
    "\n",
    "\n",
    "#     # --- Measurement Results ---\n",
    "#     table = data.get('measurement_table')\n",
    "#     # Create container only if item name exists OR table data exists\n",
    "#     if data.get('item_name') or (table and any(table.values())):\n",
    "#         meas_results = create_element(root, NS_DCC, \"measurementResults\")\n",
    "#         if meas_results is not None:\n",
    "#             meas_result = create_element(meas_results, NS_DCC, \"measurementResult\")\n",
    "#             if meas_result is not None:\n",
    "#                 create_dcc_content(meas_result, NS_DCC, \"name\", data.get('item_name'))\n",
    "\n",
    "#                 # Create results/result containers only if table data exists\n",
    "#                 if table and any(table.values()):\n",
    "#                     results = create_element(meas_result, NS_DCC, \"results\")\n",
    "#                     if results is not None:\n",
    "#                         result = create_element(results, NS_DCC, \"result\")\n",
    "#                         if result is not None:\n",
    "#                             create_dcc_content(result, NS_DCC, \"name\", \"Calibration Test Results\") # Static name for this section\n",
    "\n",
    "#                             dcc_data = create_element(result, NS_DCC, \"data\")\n",
    "#                             if dcc_data is not None:\n",
    "#                                 # Map PDF column names to XML list names and SI types\n",
    "#                                 column_map = {\n",
    "#                                     \"Applied Force\": (\"Applied Force\", \"constant\", \"kgf\"),\n",
    "#                                     \"Indicated Force\": (\"Indicated Force\", \"real\", \"kgf\"),\n",
    "#                                     \"Deviation\": (\"Deviation (Indicated Force - Applied Force)\", \"real\", \"kgf\"),\n",
    "#                                     \"Relative Expanded Uncertainty\": (\"Relative Expanded Uncertainty\", \"real\", \"%\"),\n",
    "#                                     \"Relative Accuracy Error\": (\"Relative Accuracy Error\", \"real\", \"%\"),\n",
    "#                                 }\n",
    "\n",
    "#                                 for pdf_col, (xml_name, si_type, unit) in column_map.items():\n",
    "#                                     # Check if column exists in extracted table data and has values\n",
    "#                                     if pdf_col in table and table[pdf_col]:\n",
    "#                                         dcc_list = create_element(dcc_data, NS_DCC, \"list\")\n",
    "#                                         if dcc_list is not None:\n",
    "#                                             create_dcc_content(dcc_list, NS_DCC, \"name\", xml_name)\n",
    "#                                             for value in table[pdf_col]:\n",
    "#                                                 # Ensure value is not None or empty before creating quantity\n",
    "#                                                 if value is not None and value != \"\":\n",
    "#                                                     quantity = create_element(dcc_list, NS_DCC, \"quantity\")\n",
    "#                                                     if quantity is not None:\n",
    "#                                                         si_elem = create_element(quantity, NS_SI, si_type)\n",
    "#                                                         if si_elem is not None:\n",
    "#                                                             create_element(si_elem, NS_SI, \"value\", value)\n",
    "#                                                             create_element(si_elem, NS_SI, \"unit\", unit)\n",
    "\n",
    "\n",
    "#     # --- Convert ElementTree to string with pretty printing ---\n",
    "#     try:\n",
    "#         # Use encoding='unicode' for minidom processing\n",
    "#         rough_string = ET.tostring(root, encoding='unicode', method='xml')\n",
    "#         if not rough_string:\n",
    "#              print(\"Error: XML generation resulted in an empty string.\")\n",
    "#              return\n",
    "\n",
    "#         # Add the XML declaration which ET.tostring omits\n",
    "#         xml_declaration = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n",
    "\n",
    "#         # Use minidom for pretty printing\n",
    "#         reparsed = minidom.parseString(rough_string)\n",
    "#         pretty_xml_as_string = reparsed.toprettyxml(indent=\"  \")\n",
    "\n",
    "#         # Remove the default declaration added by minidom and add ours\n",
    "#         pretty_xml_as_string = xml_declaration + '\\n'.join(pretty_xml_as_string.split('\\n')[1:])\n",
    "\n",
    "#         # Write to file\n",
    "#         with open(output_xml_path, \"w\", encoding='utf-8') as f:\n",
    "#             f.write(pretty_xml_as_string)\n",
    "#         print(f\"Successfully created pretty XML file: {output_xml_path}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error during XML generation/writing: {e}\")\n",
    "#         # Fallback: Write the non-prettified version if minidom fails\n",
    "#         try:\n",
    "#             # Re-generate rough string if needed, ensure it's unicode for writing\n",
    "#             rough_string_fallback = ET.tostring(root, encoding='unicode', method='xml')\n",
    "#             xml_declaration_fallback = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n'\n",
    "#             with open(output_xml_path, \"w\", encoding='utf-8') as f:\n",
    "#                  f.write(xml_declaration_fallback + rough_string_fallback) # Write unicode string\n",
    "#             print(f\"Successfully created basic XML file (no pretty print): {output_xml_path}\")\n",
    "#         except Exception as write_e:\n",
    "#             print(f\"Error writing basic XML file: {write_e}\")\n",
    "\n",
    "\n",
    "# # --- Main Execution ---\n",
    "# if __name__ == \"__main__\":\n",
    "#     # IMPORTANT: Replace with the actual path to your PDF file if needed\n",
    "#     pdf_input_path = \"TISSI-sample-certificate.pdf\" # Assumes file is in the same directory\n",
    "\n",
    "#     # IMPORTANT: Replace with the desired path for the output XML file\n",
    "#     xml_output_path = \"output_dcc_strict.xml\" # Changed output filename\n",
    "\n",
    "#     # 1. Extract text from PDF\n",
    "#     extracted_text = extract_text_from_pdf(pdf_input_path)\n",
    "\n",
    "#     if extracted_text:\n",
    "#         # 2. Extract specific data using patterns (strict mode)\n",
    "#         calibration_data = extract_calibration_data(extracted_text)\n",
    "\n",
    "#         # 3. Create the XML file based *only* on extracted data\n",
    "#         if calibration_data: # Check if dict is not empty\n",
    "#             create_dcc_xml(calibration_data, xml_output_path)\n",
    "#         else:\n",
    "#             print(\"No data was successfully extracted from the PDF. XML file not generated.\")\n",
    "#     else:\n",
    "#         print(\"Failed to extract text from the PDF. Cannot proceed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1cacf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xml.etree.ElementTree as ET\n",
    "# import re\n",
    "# import fitz  # Example using PyMuPDF\n",
    "# # Or: import pdfplumber # Example using pdfplumber\n",
    "# from datetime import datetime\n",
    "\n",
    "# # --- 1. Default Values & Configuration ---\n",
    "# # These might come from a config file or be hardcoded if consistent\n",
    "# DEFAULT_COUNTRY_CODE = \"PH\"\n",
    "# DEFAULT_LANG_CODE = \"en\"\n",
    "# DCC_SOFTWARE_NAME = \"YourPDFtoDCC_Converter\" # Or specific software used\n",
    "# DCC_SOFTWARE_RELEASE = \"v1.0\" # Version of your script/tool\n",
    "# SCHEMA_VERSION = \"3.2.1\" # Match the schema you are targeting\n",
    "# DCC_NAMESPACE = \"https://ptb.de/dcc\"\n",
    "# SI_NAMESPACE = \"https://ptb.de/si\"\n",
    "# XSI_NAMESPACE = \"http://www.w3.org/2001/XMLSchema-instance\"\n",
    "# SCHEMA_LOCATION = \"https://ptb.de/dcc https://ptb.de/dcc/v3.2.1/dcc.xsd\"\n",
    "\n",
    "# # Register namespaces for cleaner output (especially with lxml)\n",
    "# ET.register_namespace('dcc', DCC_NAMESPACE)\n",
    "# ET.register_namespace('si', SI_NAMESPACE)\n",
    "# ET.register_namespace('xsi', XSI_NAMESPACE)\n",
    "\n",
    "# # --- 2. Helper Functions ---\n",
    "\n",
    "# def extract_text_from_pdf(pdf_path):\n",
    "#     \"\"\"Extracts text content from all pages of a PDF.\"\"\"\n",
    "#     doc = fitz.open(pdf_path)\n",
    "#     full_text = \"\"\n",
    "#     for page_num in range(len(doc)):\n",
    "#         page = doc.load_page(page_num)\n",
    "#         full_text += page.get_text(\"text\")\n",
    "#     doc.close()\n",
    "#     return full_text\n",
    "\n",
    "# def find_value_after_keyword(text, keyword, stop_keywords=None):\n",
    "#     \"\"\"Simple regex helper to find value after a keyword until newline or stop keyword.\"\"\"\n",
    "#     # Make keyword regex safe and flexible with optional colon/space\n",
    "#     keyword_pattern = re.escape(keyword).replace('\\\\:', ':?') + r'\\s*[:]?\\s*(.*)'\n",
    "#     match = re.search(keyword_pattern, text, re.IGNORECASE | re.MULTILINE)\n",
    "#     if match:\n",
    "#         value_line = match.group(1).strip()\n",
    "#         # Optional: Stop extraction if another keyword appears on the same line\n",
    "#         if stop_keywords:\n",
    "#             for stop_kw in stop_keywords:\n",
    "#                 stop_match = re.search(re.escape(stop_kw), value_line, re.IGNORECASE)\n",
    "#                 if stop_match:\n",
    "#                     value_line = value_line[:stop_match.start()].strip()\n",
    "#                     break\n",
    "#         return value_line\n",
    "#     return None\n",
    "\n",
    "# def format_date(date_str):\n",
    "#     \"\"\"Attempts to parse date and format as YYYY-MM-DD.\"\"\"\n",
    "#     if not date_str:\n",
    "#         return None\n",
    "#     try:\n",
    "#         # Add more formats if needed\n",
    "#         date_obj = datetime.strptime(date_str.strip(), '%B %d, %Y')\n",
    "#         return date_obj.strftime('%Y-%m-%d')\n",
    "#     except ValueError:\n",
    "#         print(f\"Warning: Could not parse date '{date_str}'\")\n",
    "#         return date_str # Return original if parsing fails\n",
    "\n",
    "# def extract_table_data(pdf_path, page_num, table_settings=None):\n",
    "#     \"\"\"Extracts table data using pdfplumber (conceptual).\"\"\"\n",
    "#     # This requires pdfplumber library: pip install pdfplumber\n",
    "#     # You'll need to tune table extraction settings heavily based on PDF\n",
    "#     print(f\"Attempting table extraction on page {page_num}...\")\n",
    "#     # try:\n",
    "#     #     with pdfplumber.open(pdf_path) as pdf:\n",
    "#     #         page = pdf.pages[page_num - 1] # pdfplumber is 0-indexed\n",
    "#     #         # Example: Find table automatically (often needs tuning)\n",
    "#     #         # tables = page.extract_tables(table_settings)\n",
    "#     #         # Or define bounding box: table = page.crop((x0, top, x1, bottom)).extract_table()\n",
    "#     #         # Simplified: Assuming one main table found per page relevant section\n",
    "#     #         tables = page.extract_tables() # This needs refinement\n",
    "#     #         if tables:\n",
    "#     #              print(f\"Found {len(tables)} tables on page {page_num}.\")\n",
    "#     #              # Select the correct table based on headers or position\n",
    "#     #              # For now, assume the first relevant table\n",
    "#     #              # Clean data: remove None rows/cells, strip whitespace, handle line breaks within cells\n",
    "#     #              cleaned_table = []\n",
    "#     #              for row in tables[0]: # Assuming first table is the target\n",
    "#     #                  cleaned_row = [str(cell).strip().replace('\\n', ' ') if cell is not None else '' for cell in row]\n",
    "#     #                  if any(cleaned_row): # Skip empty rows\n",
    "#     #                      cleaned_table.append(cleaned_row)\n",
    "#     #              return cleaned_table\n",
    "#     # except Exception as e:\n",
    "#     #      print(f\"Error extracting table on page {page_num}: {e}\")\n",
    "#     return None # Placeholder\n",
    "\n",
    "# # --- 3. XML Element Creation Helpers ---\n",
    "# # These helpers make creating the nested XML structure cleaner\n",
    "\n",
    "# def create_dcc_element(tag, text=None, attrib=None, lang=None):\n",
    "#     \"\"\"Creates an element in the DCC namespace.\"\"\"\n",
    "#     if attrib is None:\n",
    "#         attrib = {}\n",
    "#     element = ET.Element(f\"{{{DCC_NAMESPACE}}}{tag}\", attrib)\n",
    "#     if text:\n",
    "#         element.text = str(text)\n",
    "#     if lang:\n",
    "#         element.set(f\"{{{ET.XML_NS}}}lang\", lang) # Use xml:lang\n",
    "#     return element\n",
    "\n",
    "# def create_si_element(tag, text=None, attrib=None):\n",
    "#      \"\"\"Creates an element in the SI namespace.\"\"\"\n",
    "#      if attrib is None:\n",
    "#          attrib = {}\n",
    "#      element = ET.Element(f\"{{{SI_NAMESPACE}}}{tag}\", attrib)\n",
    "#      if text:\n",
    "#          element.text = str(text)\n",
    "#      return element\n",
    "\n",
    "# def create_dcc_text_element(parent, tag, content, lang=DEFAULT_LANG_CODE):\n",
    "#     \"\"\"Creates standard <dcc:tag><dcc:content> structure.\"\"\"\n",
    "#     elem = create_dcc_element(tag)\n",
    "#     content_elem = create_dcc_element(\"content\", text=content, lang=lang)\n",
    "#     elem.append(content_elem)\n",
    "#     parent.append(elem)\n",
    "#     return elem\n",
    "\n",
    "# def create_si_quantity(parent_tag, value, unit):\n",
    "#     \"\"\"Creates a simple si:real or si:constant quantity element.\"\"\"\n",
    "#     # Determine if it's constant (like applied force) or real (measured)\n",
    "#     # Simple heuristic: if value contains only digits/decimal point/minus, treat as real?\n",
    "#     # Or based on parent_tag context. Here, assume 'real' for measured, 'constant' for applied.\n",
    "#     # Needs refinement based on actual schema usage.\n",
    "#     # This example uses si:real for simplicity for most measured values.\n",
    "#     # Applied Force uses si:constant as per the example XML.\n",
    "#     # Deviation could also be si:real\n",
    "\n",
    "#     if parent_tag == \"Applied Force\":\n",
    "#          q_type = \"constant\"\n",
    "#     else:\n",
    "#          q_type = \"real\" # Default assumption\n",
    "\n",
    "#     quantity_elem = create_dcc_element(\"quantity\")\n",
    "#     si_elem = create_si_element(q_type)\n",
    "#     si_value = create_si_element(\"value\", text=str(value))\n",
    "#     si_unit = create_si_element(\"unit\", text=str(unit))\n",
    "#     si_elem.append(si_value)\n",
    "#     si_elem.append(si_unit)\n",
    "#     quantity_elem.append(si_elem)\n",
    "#     return quantity_elem\n",
    "\n",
    "\n",
    "# # --- 4. Main Extraction and XML Building Logic ---\n",
    "\n",
    "# def create_dcc_from_pdf(pdf_path, output_xml_path):\n",
    "#     \"\"\"Main function to parse PDF and generate DCC XML.\"\"\"\n",
    "\n",
    "#     # --- Extract Data ---\n",
    "#     full_text = extract_text_from_pdf(pdf_path)\n",
    "#     # print(\"Extracted Text:\\n\", full_text) # For debugging\n",
    "\n",
    "#     # Extract specific fields using keywords and regex\n",
    "#     # Page 1 Data\n",
    "#     cert_no = find_value_after_keyword(full_text, \"No.\")\n",
    "#     cal_date_str = find_value_after_keyword(full_text, \"Date of Calibration\")\n",
    "#     cal_item = find_value_after_keyword(full_text, \"Calibration Item\")\n",
    "#     capacity = find_value_after_keyword(full_text, \"Capacity\", stop_keywords=[\"kgf\"]) # Simple stop example\n",
    "#     measurement_range = find_value_after_keyword(full_text, \"Measurement Range\", stop_keywords=[\"kgf\"])\n",
    "#     resolution = find_value_after_keyword(full_text, \"Resolution\", stop_keywords=[\"kgf\"])\n",
    "#     make_model = find_value_after_keyword(full_text, \"Make/Model\")\n",
    "#     serial_no = find_value_after_keyword(full_text, \"Serial No.\")\n",
    "#     customer_name = find_value_after_keyword(full_text, \"Customer\")\n",
    "#     # Customer address requires more complex multi-line parsing logic\n",
    "#     customer_address_line1 = find_value_after_keyword(full_text, customer_name) # Assuming address follows name\n",
    "#     customer_address_line2 = find_value_after_keyword(full_text, customer_address_line1) # Highly simplistic\n",
    "\n",
    "#     # Page 2 Data (Example - needs robust finding logic)\n",
    "#     # Standard Used Table Data (Requires proper table extraction)\n",
    "#     standard_name = \"Force Measuring Instrument\" # Hardcoded from PDF text/context\n",
    "#     standard_make_model = \"Shimadzu/ UH-F1000kNX\"\n",
    "#     standard_serial = \"1251056K0094\" # Extracted via keyword near standard name\n",
    "#     standard_cert_no = \"11-2020-FORC-0116\"\n",
    "\n",
    "#     # Personnel\n",
    "#     person1_name = \"AHDRIAN CAMILO C. GERNALE\" # Extract based on position or signature block\n",
    "#     person1_role = \"Science Research Specialist II\"\n",
    "#     person2_name = \"RADLEY F. MANALO\"\n",
    "#     person2_role = \"Senior Science Research Specialist\"\n",
    "#     # Add logic for Dr. Salazar if needed based on schema requirements\n",
    "\n",
    "#     # Environmental Conditions\n",
    "#     temp_str = find_value_after_keyword(full_text, \"Ambient Temperature\")\n",
    "#     humidity_str = find_value_after_keyword(full_text, \"Relative Humidity\")\n",
    "\n",
    "#     # Measurement Results Table Data (CRITICAL - Requires proper table extraction)\n",
    "#     # This needs a dedicated table extraction call, e.g.:\n",
    "#     # measurement_table = extract_table_data(pdf_path, page_num=1, table_settings={...})\n",
    "#     # Fallback/Placeholder - Use data from your example XML if table parsing fails/not implemented\n",
    "#     measurement_table = [\n",
    "#          [\"Applied Force\", \"Indicated Force\", \"Deviation (Indicated Force - Applied Force)\", \"Relative Expanded Uncertainty\", \"Relative Accuracy Error\"],\n",
    "#          [\"kgf\", \"kgf\", \"kgf\", \"%\", \"%\"], # Units row (may need special handling)\n",
    "#          [\"0.00\", \"0.00\", \"0\", \"0.00\", \"0.00\"],\n",
    "#          [\"3000\", \"2900\", \"-100\", \"1.02\", \"3.45\"], # Handle potential thousands separators if present\n",
    "#          [\"6000\", \"5900\", \"-100\", \"0.54\", \"1.69\"],\n",
    "#          [\"9000\", \"8950\", \"-50\", \"0.40\", \"0.56\"], # Handle minus sign and value merging\n",
    "#          [\"12000\", \"12000\", \"0\", \"0.34\", \"0.00\"],\n",
    "#          [\"15000\", \"15000\", \"0\", \"0.31\", \"0.00\"],\n",
    "#     ]\n",
    "#     print(\"Using placeholder measurement table data.\")\n",
    "\n",
    "\n",
    "#     # --- Build XML ---\n",
    "#     root_attrib = {\n",
    "#         f\"{{{XSI_NAMESPACE}}}schemaLocation\": SCHEMA_LOCATION,\n",
    "#         \"schemaVersion\": SCHEMA_VERSION\n",
    "#     }\n",
    "#     root = ET.Element(f\"{{{DCC_NAMESPACE}}}digitalCalibrationCertificate\", root_attrib)\n",
    "\n",
    "#     # -- Administrative Data --\n",
    "#     admin_data = create_dcc_element(\"administrativeData\")\n",
    "#     root.append(admin_data)\n",
    "\n",
    "#     # Software (Using defaults)\n",
    "#     dcc_software = create_dcc_element(\"dccSoftware\")\n",
    "#     admin_data.append(dcc_software)\n",
    "#     software = create_dcc_element(\"software\")\n",
    "#     dcc_software.append(software)\n",
    "#     create_dcc_text_element(software, \"name\", DCC_SOFTWARE_NAME)\n",
    "#     create_dcc_element(\"release\", text=DCC_SOFTWARE_RELEASE, parent=software) # Typo in example XML fixed (parent added)\n",
    "\n",
    "#     # Core Data\n",
    "#     core_data = create_dcc_element(\"coreData\")\n",
    "#     admin_data.append(core_data)\n",
    "#     create_dcc_element(\"countryCodeISO3166_1\", text=DEFAULT_COUNTRY_CODE, parent=core_data)\n",
    "#     create_dcc_element(\"usedLangCodeISO639_1\", text=DEFAULT_LANG_CODE, parent=core_data)\n",
    "#     create_dcc_element(\"mandatoryLangCodeISO639_1\", text=DEFAULT_LANG_CODE, parent=core_data)\n",
    "#     create_dcc_element(\"uniqueIdentifier\", text=cert_no, parent=core_data)\n",
    "#     create_dcc_element(\"beginPerformanceDate\", text=format_date(cal_date_str), parent=core_data)\n",
    "#     create_dcc_element(\"endPerformanceDate\", text=format_date(cal_date_str), parent=core_data) # Assuming same day\n",
    "#     create_dcc_element(\"performanceLocation\", text=\"laboratory\", parent=core_data) # From PDF context\n",
    "\n",
    "#     # Items\n",
    "#     items = create_dcc_element(\"items\")\n",
    "#     admin_data.append(items)\n",
    "#     create_dcc_text_element(items, \"name\", cal_item, lang=DEFAULT_LANG_CODE) # Name for the list\n",
    "#     # You might add equipmentClass here if applicable to the whole list\n",
    "\n",
    "#     item = create_dcc_element(\"item\") # The actual calibrated item\n",
    "#     items.append(item)\n",
    "#     create_dcc_text_element(item, \"name\", cal_item, lang=DEFAULT_LANG_CODE) # Name for the specific item\n",
    "#     # Add Manufacturer / Model if available separately\n",
    "#     if make_model:\n",
    "#          # Simple splitting, might need refinement\n",
    "#          parts = make_model.split('/', 1)\n",
    "#          item_manufacturer_name = parts[0].strip() if len(parts) > 0 else make_model\n",
    "#          item_model_name = parts[1].strip() if len(parts) > 1 else None\n",
    "\n",
    "#          # Manufacturer (structure depends on exact schema - using contactNotStrictType idea)\n",
    "#          # manufacturer_elem = create_dcc_element(\"manufacturer\")\n",
    "#          # create_dcc_text_element(manufacturer_elem, \"name\", item_manufacturer_name)\n",
    "#          # item.append(manufacturer_elem) # Add if schema requires\n",
    "\n",
    "#          if item_model_name:\n",
    "#              create_dcc_element(\"model\", text=item_model_name, parent=item)\n",
    "\n",
    "#     # Item Identifications (Serial No.)\n",
    "#     identifications = create_dcc_element(\"identifications\")\n",
    "#     item.append(identifications)\n",
    "#     identification = create_dcc_element(\"identification\")\n",
    "#     identifications.append(identification)\n",
    "#     create_dcc_element(\"issuer\", text=\"manufacturer\", parent=identification) # Assuming manufacturer issued SN\n",
    "#     create_dcc_element(\"value\", text=serial_no, parent=identification)\n",
    "#     create_dcc_text_element(identification, \"name\", \"Serial Number\", lang=DEFAULT_LANG_CODE)\n",
    "\n",
    "#     # Calibration Laboratory (Partially hardcoded based on context/example)\n",
    "#     calib_lab = create_dcc_element(\"calibrationLaboratory\")\n",
    "#     admin_data.append(calib_lab)\n",
    "#     # Add calibrationLaboratoryCode if known/consistent, e.g., \"FORC\"\n",
    "#     create_dcc_element(\"calibrationLaboratoryCode\", text=\"FORC\", parent=calib_lab)\n",
    "#     contact_lab = create_dcc_element(\"contact\")\n",
    "#     calib_lab.append(contact_lab)\n",
    "#     create_dcc_text_element(contact_lab, \"name\", \"NML-ITDI\") # From context/example\n",
    "#     location_lab = create_dcc_element(\"location\")\n",
    "#     contact_lab.append(location_lab)\n",
    "#     create_dcc_element(\"city\", text=\"Taguig\", parent=location_lab) # Context/Example\n",
    "#     create_dcc_element(\"countryCode\", text=DEFAULT_COUNTRY_CODE, parent=location_lab)\n",
    "#     # Add postCode, street etc. if available and required by schema\n",
    "\n",
    "#     # Responsible Persons\n",
    "#     resp_persons = create_dcc_element(\"respPersons\")\n",
    "#     admin_data.append(resp_persons)\n",
    "#     # Person 1\n",
    "#     resp_person1 = create_dcc_element(\"respPerson\")\n",
    "#     resp_persons.append(resp_person1)\n",
    "#     person1 = create_dcc_element(\"person\")\n",
    "#     resp_person1.append(person1)\n",
    "#     create_dcc_text_element(person1, \"name\", person1_name, lang=DEFAULT_LANG_CODE)\n",
    "#     create_dcc_element(\"role\", text=person1_role, parent=resp_person1)\n",
    "#     # Person 2\n",
    "#     resp_person2 = create_dcc_element(\"respPerson\")\n",
    "#     resp_persons.append(resp_person2)\n",
    "#     person2 = create_dcc_element(\"person\")\n",
    "#     resp_person2.append(person2)\n",
    "#     create_dcc_text_element(person2, \"name\", person2_name, lang=DEFAULT_LANG_CODE)\n",
    "#     create_dcc_element(\"role\", text=person2_role, parent=resp_person2)\n",
    "#     # Add Dr. Salazar similarly if needed\n",
    "\n",
    "#     # Customer\n",
    "#     customer = create_dcc_element(\"customer\")\n",
    "#     admin_data.append(customer)\n",
    "#     create_dcc_text_element(customer, \"name\", customer_name, lang=DEFAULT_LANG_CODE)\n",
    "#     location_cust = create_dcc_element(\"location\")\n",
    "#     customer.append(location_cust)\n",
    "#     # Parse and add address components (city, street, postCode, countryCode)\n",
    "#     # Simple example based on limited parsing:\n",
    "#     create_dcc_element(\"street\", text=customer_address_line1, parent=location_cust) # Needs proper parsing\n",
    "#     # create_dcc_element(\"city\", text=\"Marikina\", parent=location_cust) # Needs extraction\n",
    "#     create_dcc_element(\"countryCode\", text=DEFAULT_COUNTRY_CODE, parent=location_cust)\n",
    "\n",
    "\n",
    "#     # -- Measurement Results --\n",
    "#     meas_results_list = create_dcc_element(\"measurementResults\")\n",
    "#     root.append(meas_results_list)\n",
    "\n",
    "#     # Add usedMethods, measuringEquipments (Standard Used), influenceConditions here\n",
    "#     # Example: Influence Condition Temp\n",
    "#     # influence_conditions = create_dcc_element(\"influenceConditions\")\n",
    "#     # meas_results_list.append(influence_conditions)\n",
    "#     # temp_cond = create_dcc_element(\"influenceCondition\")\n",
    "#     # influence_conditions.append(temp_cond)\n",
    "#     # create_dcc_text_element(temp_cond, \"name\", \"Ambient Temperature\")\n",
    "#     # temp_data = create_dcc_element(\"data\")\n",
    "#     # temp_cond.append(temp_data)\n",
    "#     # # Needs parsing of value/uncertainty from temp_str to create si:hybrid or si:real + uncertainty\n",
    "#     # # Placeholder: create_dcc_element(\"text\", text=temp_str, parent=temp_data)\n",
    "\n",
    "\n",
    "#     # Main Measurement Result Section (Processing the table)\n",
    "#     meas_result = create_dcc_element(\"measurementResult\")\n",
    "#     meas_results_list.append(meas_result)\n",
    "#     create_dcc_text_element(meas_result, \"name\", cal_item, lang=DEFAULT_LANG_CODE) # Name for this result set\n",
    "\n",
    "#     results = create_dcc_element(\"results\")\n",
    "#     meas_result.append(results)\n",
    "#     result = create_dcc_element(\"result\") # The overall table result\n",
    "#     results.append(result)\n",
    "#     create_dcc_text_element(result, \"name\", \"Calibration Test Results\", lang=DEFAULT_LANG_CODE)\n",
    "\n",
    "#     data = create_dcc_element(\"data\") # Container for the lists (columns)\n",
    "#     result.append(data)\n",
    "\n",
    "#     if measurement_table and len(measurement_table) > 2: # Check if table has header, units, and data\n",
    "#         headers = measurement_table[0]\n",
    "#         units = measurement_table[1]\n",
    "#         num_cols = len(headers)\n",
    "#         num_rows = len(measurement_table) - 2 # Exclude header and unit rows\n",
    "\n",
    "#         for col_idx in range(num_cols):\n",
    "#             list_elem = create_dcc_element(\"list\")\n",
    "#             data.append(list_elem)\n",
    "#             create_dcc_text_element(list_elem, \"name\", headers[col_idx], lang=DEFAULT_LANG_CODE)\n",
    "\n",
    "#             col_unit = units[col_idx]\n",
    "#             parent_tag_context = headers[col_idx] # Use header name for context\n",
    "\n",
    "#             for row_idx in range(num_rows):\n",
    "#                 data_row_idx = row_idx + 2 # Offset by header/unit rows\n",
    "#                 value_str = measurement_table[data_row_idx][col_idx]\n",
    "#                 # Clean value (remove commas, handle potential issues)\n",
    "#                 cleaned_value = value_str.replace(',', '').strip()\n",
    "#                 try:\n",
    "#                     # Attempt conversion to float for numeric check, but keep string for XML\n",
    "#                     float(cleaned_value)\n",
    "#                     q_elem = create_si_quantity(parent_tag_context, cleaned_value, col_unit)\n",
    "#                     list_elem.append(q_elem)\n",
    "#                 except ValueError:\n",
    "#                     print(f\"Warning: Could not convert value '{cleaned_value}' to number in {headers[col_idx]}. Storing as text or skipping.\")\n",
    "#                     # Optionally add as text or handle error\n",
    "\n",
    "\n",
    "#     # --- Serialize and Save XML ---\n",
    "#     tree = ET.ElementTree(root)\n",
    "#     ET.indent(tree, space=\"  \", level=0) # Pretty print\n",
    "#     tree.write(output_xml_path, encoding=\"UTF-8\", xml_declaration=True)\n",
    "#     print(f\"DCC XML saved to: {output_xml_path}\")\n",
    "\n",
    "\n",
    "# # --- Run the process ---\n",
    "# pdf_file = \"TISSI-sample-certificate.pdf\" # Make sure this path is correct\n",
    "# output_xml_file = \"TISSI-sample-certificate.xml\"\n",
    "\n",
    "# # Make sure the PDF file exists before running\n",
    "# import os\n",
    "# if os.path.exists(pdf_file):\n",
    "#     create_dcc_from_pdf(pdf_file, output_xml_file)\n",
    "# else:\n",
    "#     print(f\"Error: PDF file not found at {pdf_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f073fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_7896\\3157091896.py:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  pdf_path = \"valid pdf\\TISSI-sample-certificate.pdf\"\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_7896\\3157091896.py:7: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  output_pdf_path = \"valid pdf\\TISSI-sample-certificate_blocks.pdf\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened PDF: 'valid pdf\\TISSI-sample-certificate.pdf'. Processing 2 pages...\n",
      "  Page 1: Found 25 blocks.\n",
      "  Page 2: Found 26 blocks.\n",
      "\n",
      "An error occurred during PDF processing: code=2: cannot remove file 'valid pdf\\TISSI-sample-certificate_blocks.pdf': Permission denied\n",
      "\n",
      "--- Detected Text Blocks (Start of content) ---\n",
      "  Block 1: CALIBRATION CERTIFICATE...\n",
      "  Block 2: No. 01-2025-FORC-0013...\n",
      "  Block 3: February 24, 2025 Axle Weighing Scale 15 000 kgf 0 kgf to 15 000 kgf 50 kgf APOL...\n",
      "  Block 4: Date of Calibration : Calibration Item : Capacity : Measurement Range : Resoluti...\n",
      "  Block 5: Marikina, Eastern Manila District, NCR...\n",
      "  Block 6: MEASUREMENT RESULTS:...\n",
      "  Block 7: Relative  Expanded  Uncertainty...\n",
      "  Block 8: Relative  Accuracy...\n",
      "  Block 9: Deviation (Indicated Force -...\n",
      "  Block 10: Applied...\n",
      "  Block 11: Indicated...\n",
      "  Block 12: Force...\n",
      "  Block 13: Force...\n",
      "  Block 14: Error...\n",
      "  Block 15: Applied Force)...\n",
      "  Block 16: kgf kgf kgf % %...\n",
      "  Block 17: 0.00 0.00 0 0.00 0.00...\n",
      "  Block 18: 3 000 2 900 -100 1.02 3.45...\n",
      "  Block 19: 6 000 5 900 -100 0.54 1.69...\n",
      "  Block 20: 9 000 8 950 -50 0.40 0.56...\n",
      "  Block 21: 12 000 12 000 0 0.34 0.00...\n",
      "  Block 22: 15 000 15 000 0 0.31 0.00...\n",
      "  Block 23: UNCERTAINTY OF MEASUREMENT:...\n",
      "  Block 24: The uncertainty stated is the expanded uncertainty obtained by multiplying the s...\n",
      "  Block 25: Page 1 of 2...\n",
      "  Block 26: STANDARD USED :...\n",
      "  Block 27: Name of Standard Make/Model Calibration Certificate No. Traceability...\n",
      "  Block 28: Force Measuring...\n",
      "  Block 29: Shimadzu/ UH-...\n",
      "  Block 30: F1000kNX 11-2020-FORC-0116 Traceable to the SI  through NMD-ITDI...\n",
      "  Block 31: Instrument SN 1251056K0094...\n",
      "  Block 32: CALIBRATION PROCEDURE:...\n",
      "  Block 33: The axle weighing scale was subjected to specified force values in comparison wi...\n",
      "  Block 34: The relevant references for this axle weighing scale calibration are the TP-S3-F...\n",
      "  Block 35: ENVIRONMENTAL CONDITIONS:...\n",
      "  Block 36: Ambient Temperature Relative Humidity...\n",
      "  Block 37: :   (22 ± 2)   :   (41 ± 5)...\n",
      "  Block 38: REMARKS:...\n",
      "  Block 39: The above results were those obtained at the time of calibration and refer only ...\n",
      "  Block 40: -...\n",
      "  Block 41: -...\n",
      "  Block 42: No adjustment was performed on the axle weighing scale. The user should determin...\n",
      "  Block 43: AHDRIAN CAMILO C. GERNALE...\n",
      "  Block 44: Science Research Specialist II...\n",
      "  Block 45: RADLEY F. MANALO...\n",
      "  Block 46: Senior Science Research Specialist...\n",
      "  Block 47: For the Chief, National Metrology Laboratory...\n",
      "  Block 48: MARYNESS I. SALAZAR, PhD Head, Pressure and Force Standards Section Date issued:...\n",
      "  Block 49: -End of Report-...\n",
      "  Block 50: Page 2 of 2...\n",
      "  Block 51: Calibration Certificate No. 01-2025-FORC-0013...\n",
      "\n",
      "Enter a block number to see its full text, or 'q' to quit.\n",
      "\n",
      "Exiting.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "pdf_path = \"valid pdf\\TISSI-sample-certificate.pdf\"\n",
    "output_pdf_path = \"valid pdf\\TISSI-sample-certificate_blocks.pdf\"\n",
    "box_color = (1, 0, 0)  # Red (RGB, values 0-1)\n",
    "text_color = (1, 0, 0) # Red for the number\n",
    "box_width = 0.5\n",
    "font_size = 6\n",
    "\n",
    "# --- Check if PDF exists ---\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\"Error: Input PDF file not found at '{pdf_path}'\")\n",
    "    sys.exit(1)\n",
    "\n",
    "#\n",
    "all_blocks_text = []\n",
    "block_counter = 0\n",
    "\n",
    "try:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    print(f\"Opened PDF: '{pdf_path}'. Processing {len(doc)} pages...\")\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        \n",
    "        blocks = page.get_text(\"blocks\")\n",
    "        blocks.sort(key=lambda b: (b[1], b[0])) # Sort blocks top-to-bottom, left-to-right\n",
    "\n",
    "        print(f\"  Page {page_num + 1}: Found {len(blocks)} blocks.\")\n",
    "\n",
    "        for i, b in enumerate(blocks):\n",
    "            block_counter += 1\n",
    "            x0, y0, x1, y1, text_content, _, _ = b\n",
    "\n",
    "            # Store text content\n",
    "            clean_text = text_content.strip()\n",
    "            all_blocks_text.append(clean_text)\n",
    "\n",
    "            # Draw bounding box rectangle\n",
    "            rect = fitz.Rect(x0, y0, x1, y1)\n",
    "            page.draw_rect(rect, color=box_color, width=box_width)\n",
    "\n",
    "            # Draw block number near the top-left corner\n",
    "            text_pos = fitz.Point(x0 + 1, y0 + font_size + 1) # Position slightly inside top-left\n",
    "            page.insert_text(text_pos,\n",
    "                              f\"{block_counter}\",\n",
    "                              fontsize=font_size,\n",
    "                              color=text_color,\n",
    "                              rotate=0)\n",
    "\n",
    "    # Save the modified document\n",
    "    doc.save(output_pdf_path, garbage=4, deflate=True)\n",
    "    print(f\"\\nSuccessfully saved highlighted PDF to: '{output_pdf_path}'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred during PDF processing: {e}\")\n",
    "finally:\n",
    "    if 'doc' in locals() and doc:\n",
    "        doc.close()\n",
    "\n",
    "# --- Interactive Block Text Display ---\n",
    "if not all_blocks_text:\n",
    "    print(\"No text blocks were extracted.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"\\n--- Detected Text Blocks (Start of content) ---\")\n",
    "for i, text in enumerate(all_blocks_text):\n",
    "    snippet = text.replace('\\n', ' ').strip()\n",
    "    print(f\"  Block {i + 1}: {snippet[:80]}...\") # Print first 80 chars\n",
    "\n",
    "print(\"\\nEnter a block number to see its full text, or 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(f\"Enter block number (1-{len(all_blocks_text)}) or 'q': \").strip()\n",
    "\n",
    "        if user_input.lower() == 'q':\n",
    "            break\n",
    "\n",
    "        block_index = int(user_input) - 1 # Convert to 0-based index\n",
    "\n",
    "        if 0 <= block_index < len(all_blocks_text):\n",
    "            print(\"-\" * 20 + f\" Block {block_index + 1} Text \" + \"-\" * 20)\n",
    "            print(all_blocks_text[block_index])\n",
    "            print(\"-\" * (42 + len(str(block_index + 1)))) # Match dashes width\n",
    "        else:\n",
    "            print(f\"Invalid input. Please enter a number between 1 and {len(all_blocks_text)} or 'q'.\")\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a number or 'q'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "print(\"\\nExiting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660822d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
