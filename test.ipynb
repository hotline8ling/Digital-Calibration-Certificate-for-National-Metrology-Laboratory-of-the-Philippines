{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd1d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "from reportlab.pdfgen import canvas\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import layoutparser as lp\n",
    "from table_transformer import TableExtractionPipeline\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Adjust if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8595a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running OCR on image...\n",
      "✅ Searchable PDF saved to: output/exp/hyper/new-output.pdf\n",
      "Searchable PDF created!\n",
      "Detection model initialized.\n",
      "Detection model weights loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure model initialized.\n",
      "Structure model weights loaded.\n",
      "OCR reader initialized.\n",
      "'numpy.ndarray' object has no attribute 'read'\n",
      "Table 0 is None and will be skipped.\n",
      "Table 1 is None and will be skipped.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 110\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearchable PDF created!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Table detection\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m \u001b[43mdetect_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable detection completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 24\u001b[0m, in \u001b[0;36mdetect_tables\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Ensure the table is not None\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Save the table as CSV\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput/exp/hyper/table_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 24\u001b[0m     \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m(csv_path)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "print('Running OCR on image...')\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Gentle denoising\n",
    "    denoised = cv2.fastNlMeansDenoisingColored(image, None, 5, 10, 7, 21)\n",
    "\n",
    "    # Convert to LAB and enhance contrast\n",
    "    lab = cv2.cvtColor(denoised, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    merged = cv2.merge((cl, a, b))\n",
    "    enhanced = cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # Save preprocessed image\n",
    "    os.makedirs(\"output/exp/hyper\", exist_ok=True)\n",
    "    cv2.imwrite(\"output/exp/hyper/new-prepro-img.jpg\", enhanced)\n",
    "\n",
    "    return image, enhanced\n",
    "\n",
    "\n",
    "def image_to_searchable_pdf(image_path, pdf_path):\n",
    "    original_img, preprocessed_img = preprocess_image(image_path)\n",
    "\n",
    "    height, width = original_img.shape[:2]\n",
    "\n",
    "    # Save original image as RGB for the PDF background\n",
    "    temp_image_path = \"temp_image.jpg\"\n",
    "    Image.fromarray(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)).save(temp_image_path)\n",
    "\n",
    "    # Use Tesseract to extract layout-aware data\n",
    "    custom_config = r'--oem 3 --psm 12 -l eng'\n",
    "    pil_image = Image.fromarray(preprocessed_img)\n",
    "    data = pytesseract.image_to_data(pil_image, output_type=pytesseract.Output.DICT, config=custom_config)\n",
    "\n",
    "    # Create canvas with same size as image\n",
    "    c = canvas.Canvas(pdf_path, pagesize=(width, height))\n",
    "    c.drawImage(temp_image_path, 0, 0, width=width, height=height)\n",
    "\n",
    "    # Transparent text overlay\n",
    "    c.setFillColorRGB(255, 255, 255, alpha=1)\n",
    "    c.setFont(\"Helvetica\", 20)\n",
    "\n",
    "    # Group words by line\n",
    "    lines = {}\n",
    "    for i in range(len(data['text'])):\n",
    "        if int(data['conf'][i]) > 60 and data['text'][i].strip():\n",
    "            key = (data['block_num'][i], data['par_num'][i], data['line_num'][i])\n",
    "            if key not in lines:\n",
    "                lines[key] = []\n",
    "            lines[key].append(i)\n",
    "\n",
    "    for key in lines:\n",
    "        word_indices = lines[key]\n",
    "        line_text = \" \".join([data['text'][i] for i in word_indices])\n",
    "        x = min([data['left'][i] for i in word_indices])\n",
    "\n",
    "        # Use average for better alignment\n",
    "        avg_top = int(np.mean([data['top'][i] for i in word_indices]))\n",
    "        avg_height = int(np.mean([data['height'][i] for i in word_indices]))\n",
    "\n",
    "        # Optional tweak: small offset to better center text\n",
    "        y_adjusted = height - avg_top - int(avg_height * 0.8)\n",
    "\n",
    "        c.drawString(x, y_adjusted, line_text)\n",
    "\n",
    "\n",
    "    c.save()\n",
    "    os.remove(temp_image_path)\n",
    "    print(f\"✅ Searchable PDF saved to: {pdf_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_to_searchable_pdf(\"input/cert.jpg\", \"output/exp/hyper/new-output.pdf\")\n",
    "    print(\"Searchable PDF created!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
